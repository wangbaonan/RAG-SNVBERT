# è®­ç»ƒä¼˜åŒ–æ€»ç»“ - ä¿®å¤è®­ç»ƒåœæ»é—®é¢˜

## ğŸ” é—®é¢˜è¯Šæ–­

### è§‚å¯Ÿåˆ°çš„ç—‡çŠ¶
1. **è®­ç»ƒåœ¨Epoch 2ååœæ»**
   - Epoch 1: Train F1 = 92.3%, Loss = 24.86
   - Epoch 2: Train F1 = 97.76%, Loss = 14.90 (å·¨å¤§è·³è·ƒ)
   - Epoch 3-6: Train F1 = ~97.75%, Loss = ~14.9 (å®Œå…¨å¹³å¦)

2. **éªŒè¯é›†æŒ‡æ ‡å®Œå…¨ä¸å˜**
   - Rare F1: 0.9514508247375488 (16ä½å°æ•°å®Œå…¨ä¸€è‡´)
   - Common F1: 0.9807226061820984 (æ¯ä¸ªepochå®Œå…¨ç›¸åŒ)

### æ ¹æœ¬åŸå› åˆ†æ

#### 1. Focal Loss Gammaè¿‡é«˜ (gamma=5)
```python
# åŸä»£ç 
FocalLoss(gamma=5)  # è¿‡åº¦å…³æ³¨éš¾æ ·æœ¬
```

**é—®é¢˜**:
- Focal Losså…¬å¼: `FL = -(1-p)^gamma * log(p)`
- gamma=5æ—¶,å¯¹äºp=0.9çš„æ ·æœ¬: `(1-0.9)^5 = 0.00001` (æ¢¯åº¦å‡ ä¹ä¸º0)
- ä¸€æ—¦æ¨¡å‹è¾¾åˆ°~98%å‡†ç¡®ç‡,å‡ ä¹æ‰€æœ‰æ ·æœ¬çš„æ¢¯åº¦éƒ½æ¥è¿‘0
- æ¨¡å‹åœæ­¢å­¦ä¹ 

**æ ‡å‡†å€¼å¯¹æ¯”**:
- **è®ºæ–‡æ¨è**: gamma=2 (Focal LossåŸè®ºæ–‡)
- **ç›®å‰ä½¿ç”¨**: gamma=5 (è¿‡äºæ¿€è¿›)
- **ä¼˜åŒ–å€¼**: gamma=2.5 (æŠ˜ä¸­æ–¹æ¡ˆ)

#### 2. Reconstruction Lossæ¢¯åº¦å†²çª

```python
# åŸä»£ç  - ä¸¤ä¸ªç›¸åçš„ç›®æ ‡
recon_loss = MSE(transformed_emb, original_emb)  # å¸Œæœ›embeddingä¸å˜
prediction_loss = CrossEntropy(...)              # å¸Œæœ›embeddingæ”¹å˜ä»¥æ›´å¥½é¢„æµ‹
```

**é—®é¢˜**:
- **Recon loss**: å¸Œæœ›Transformerä¸æ”¹å˜embedding (MSEæœ€å°åŒ–)
- **Prediction loss**: å¸Œæœ›Transformeræ”¹å˜embeddingæ¥é¢„æµ‹mask (å‡†ç¡®ç‡æœ€å¤§åŒ–)
- ä¸¤ä¸ªlossçš„æ¢¯åº¦æ–¹å‘ç›¸å,å¯¼è‡´ä¼˜åŒ–å›°éš¾

**å®éªŒè¯æ®**:
```python
# åŸlossæƒé‡
total_loss = 0.2*hap1 + 0.2*hap2 + 0.3*gt + 0.15*recon1 + 0.15*recon2
# reconå æ¯” 30%, é˜»ç¢äº†é¢„æµ‹ä»»åŠ¡çš„å­¦ä¹ 
```

#### 3. å­¦ä¹ ç‡è¿‡ä½

```python
lr = 1e-5  # åŸå€¼
warmup_steps = 20000  # åŸå€¼
```

**é—®é¢˜**:
- ä¸Focal gamma=5ç»“åˆæ—¶,æ¢¯åº¦å·²ç»å¾ˆå°
- å­¦ä¹ ç‡å†å¾ˆå°,æƒé‡æ›´æ–°å¹…åº¦å¾®ä¹å…¶å¾®
- å¯¼è‡´æ¨¡å‹å¿«é€Ÿæ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜

---

## âœ… ä¼˜åŒ–æ–¹æ¡ˆ

### æ ¸å¿ƒæ”¹åŠ¨

| å‚æ•° | åŸå€¼ | ä¼˜åŒ–å€¼ | ç†ç”± |
|------|------|--------|------|
| `focal_gamma` | 5 | 2.5 | å‡è½»éš¾æ ·æœ¬è¿‡åº¦å…³æ³¨,ä¿æŒæ¢¯åº¦æµåŠ¨ |
| `use_recon_loss` | true | false | é¿å…æ¢¯åº¦å†²çª |
| `learning_rate` | 1e-5 | 5e-5 | åŠ å¿«å­¦ä¹ ,é…åˆé™ä½çš„gamma |
| `warmup_steps` | 20000 | 10000 | æ›´å¿«è¿›å…¥ç¨³å®šå­¦ä¹ é˜¶æ®µ |

### ä»£ç å®ç°

#### 1. æ–°å¢å¯é…ç½®å‚æ•° ([train_with_val_optimized.py](src/train_with_val_optimized.py))

```python
parser.add_argument("--focal_gamma", type=float, default=2.5,
                   help="Focal Loss gamma (é»˜è®¤2.5, åŸç‰ˆ5)")
parser.add_argument("--use_recon_loss", type=str, default="false",
                   choices=["true", "false"],
                   help="æ˜¯å¦ä½¿ç”¨reconstruction loss (é»˜è®¤false)")
parser.add_argument("--lr", type=float, default=5e-5,
                   help="å­¦ä¹ ç‡ (ä¼˜åŒ–: 5e-5)")
```

#### 2. ä¿®æ”¹Trainerç±» ([pretrain_with_val_optimized.py](src/main/pretrain_with_val_optimized.py))

```python
class BERTTrainerWithValidationOptimized:
    def __init__(
        self,
        # ... å…¶ä»–å‚æ•°
        focal_gamma: float = 2.5,      # æ–°å¢
        use_recon_loss: bool = False,  # æ–°å¢
        lr: float = 5e-5,              # ä¿®æ”¹é»˜è®¤å€¼
        warmup_steps=10000,            # ä¿®æ”¹é»˜è®¤å€¼
    ):
        # ä½¿ç”¨å¯é…ç½®çš„focal gamma
        self.hap_criterion = FocalLoss(gamma=focal_gamma, reduction='sum')
        self.gt_criterion = FocalLoss(gamma=focal_gamma, reduction='sum')

        # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦ä½¿ç”¨recon loss
        if self.use_recon_loss:
            # ... è®¡ç®—recon loss
        else:
            total_loss = 3 * hap_1_loss + 3 * hap_2_loss + 4 * gt_loss
```

#### 3. æ–°å¢è¿è¡Œè„šæœ¬ ([run_v13_optimized.sh](run_v13_optimized.sh))

```bash
python -m src.train_with_val_optimized \
    --focal_gamma 2.5 \
    --use_recon_loss false \
    --lr 5e-5 \
    --warmup_steps 10000 \
    --rare_threshold 0.05 \
    --metrics_csv ${METRICS_CSV} \
    # ... å…¶ä»–å‚æ•°
```

---

## ğŸ§ª é¢„æœŸæ•ˆæœ

### è®­ç»ƒè¡Œä¸ºæ”¹å˜

**ä¹‹å‰ (gamma=5 + recon loss)**:
```
Epoch 1: Loss 24.86 â†’ F1 92.3%
Epoch 2: Loss 14.90 â†’ F1 97.76%  â† å·¨å¤§è·³è·ƒååœæ»
Epoch 3-6: Loss ~14.9 â†’ F1 ~97.75%  â† å®Œå…¨ä¸åŠ¨
```

**ä¼˜åŒ–å (gamma=2.5, no recon)**:
```
Epoch 1: Loss åº”è¯¥æ›´é«˜ (æ›´å¤šæ¢¯åº¦æµåŠ¨)
Epoch 2-6: Loss åº”è¯¥é€æ¸ä¸‹é™ (æŒç»­å­¦ä¹ )
Epoch 10+: å¯èƒ½è¾¾åˆ°æ›´é«˜F1 (98%+)
```

### éªŒè¯é›†è¡Œä¸ºæ”¹å˜

**ä¹‹å‰**:
- Rare F1: 0.9514508... (å®Œå…¨ä¸å˜,16ä½å°æ•°ä¸€è‡´)
- Common F1: 0.9807226... (å®Œå…¨ä¸å˜)

**ä¼˜åŒ–å**:
- åº”è¯¥çœ‹åˆ°è½»å¾®æ³¢åŠ¨ (Â±0.001-0.01)
- å¯èƒ½æ•´ä½“è¶‹åŠ¿ä¸Šå‡
- ä¸åº”è¯¥16ä½å°æ•°å®Œå…¨ç›¸åŒ

### Lossæ›²çº¿æ”¹å˜

**ä¹‹å‰**:
```
Loss: 24.86 â†’ 14.90 â†’ 14.9 â†’ 14.9 â†’ ... (Lå½¢æ›²çº¿)
```

**ä¼˜åŒ–å**:
```
Loss: åº”è¯¥å¹³æ»‘ä¸‹é™ (é€æ¸æ”¶æ•›æ›²çº¿)
```

---

## ğŸ“Š å¦‚ä½•éªŒè¯ä¼˜åŒ–æ•ˆæœ

### 1. è¿è¡Œä¼˜åŒ–ç‰ˆè®­ç»ƒ

```bash
# åœ¨æœåŠ¡å™¨ä¸Š
cd /cpfs01/projects-HDD/.../00_RAG-SNVBERT-packup
git pull origin main
bash run_v13_optimized.sh
```

### 2. ç›‘æ§å…³é”®æŒ‡æ ‡

#### å®æ—¶ç›‘æ§ (è®­ç»ƒä¸­)
```bash
# æŸ¥çœ‹å®æ—¶æ—¥å¿—
tail -f logs/optimized_gamma25_norecon/latest.log | grep "Epoch"

# æŸ¥çœ‹Rare vs Common F1
tail -f logs/optimized_gamma25_norecon/latest.log | grep -E "(Rare|Common) Variants"
```

#### è®­ç»ƒååˆ†æ
```bash
# ç”Ÿæˆå›¾è¡¨
python scripts/plot_metrics_csv.py metrics/optimized_gamma25_norecon/latest.csv

# æŸ¥çœ‹CSV
head -20 metrics/optimized_gamma25_norecon/latest.csv
```

### 3. å¯¹æ¯”åŸºçº¿vsä¼˜åŒ–

| æŒ‡æ ‡ | åŸºçº¿ (gamma=5) | ä¼˜åŒ– (gamma=2.5) | æœŸæœ›æ”¹è¿› |
|------|---------------|------------------|----------|
| Epoch 6 Train F1 | 97.75% | ? | æŒç»­ä¸Šå‡ |
| Epoch 6 Val F1 | 97.8% (ä¸å˜) | ? | æœ‰æ³¢åŠ¨ |
| Lossæ›²çº¿ | Lå½¢ (å¿«é€Ÿåœæ») | ? | å¹³æ»‘ä¸‹é™ |
| Rare F1 | 95.1% (ä¸å˜) | ? | å¯èƒ½æ›´é«˜ |

---

## ğŸš€ è¿è¡Œæ­¥éª¤

### æœåŠ¡å™¨ç«¯æ“ä½œ

```bash
# 1. æ‹‰å–æœ€æ–°ä»£ç 
cd /cpfs01/projects-HDD/humPOG_HDD/wbn_24110700074/RAG_Version/VCF-Bert/00_RAG-SNVBERT-packup
git pull origin main

# 2. éªŒè¯æ–‡ä»¶å­˜åœ¨
ls -lh src/train_with_val_optimized.py
ls -lh src/main/pretrain_with_val_optimized.py
ls -lh run_v13_optimized.sh

# 3. è¿è¡Œä¼˜åŒ–ç‰ˆè®­ç»ƒ
bash run_v13_optimized.sh

# 4. å®æ—¶ç›‘æ§
# åœ¨å¦ä¸€ä¸ªç»ˆç«¯ä¸­:
tail -f logs/optimized_gamma25_norecon/latest.log
```

### è¾“å‡ºæ–‡ä»¶ä½ç½®

```
logs/optimized_gamma25_norecon/
â”œâ”€â”€ training_YYYYMMDD_HHMMSS.log  # å®Œæ•´è®­ç»ƒæ—¥å¿—
â””â”€â”€ latest.log                     # ç¬¦å·é“¾æ¥åˆ°æœ€æ–°æ—¥å¿—

metrics/optimized_gamma25_norecon/
â”œâ”€â”€ metrics_YYYYMMDD_HHMMSS.csv   # CSVæŒ‡æ ‡
â””â”€â”€ latest.csv                     # ç¬¦å·é“¾æ¥åˆ°æœ€æ–°CSV

/cpfs01/.../output_optimized/
â””â”€â”€ rag_bert.model.ep*             # æ¨¡å‹checkpoint
```

---

## ğŸ”¬ æŠ€æœ¯ç»†èŠ‚

### Focal Lossæ•°å­¦æ¨å¯¼

```
æ ‡å‡†CE Loss: L_CE = -log(p)

Focal Loss: L_FL = -(1-p)^Î³ * log(p)

å½“pæ¥è¿‘1æ—¶ (æ¨¡å‹é¢„æµ‹å‡†ç¡®):
  Î³=0:  (1-0.9)^0 = 1.0     â†’ æ¢¯åº¦æ­£å¸¸
  Î³=2:  (1-0.9)^2 = 0.01    â†’ æ¢¯åº¦å‡å°100å€
  Î³=5:  (1-0.9)^5 = 0.00001 â†’ æ¢¯åº¦å‡å°10ä¸‡å€ âš ï¸

ç»“è®º: Î³=5æ—¶,ä¸€æ—¦å‡†ç¡®ç‡>95%,æ¢¯åº¦å‡ ä¹æ¶ˆå¤±
```

### Reconstruction Losså†²çªè¯æ®

```python
# Forward pass
x = original_embedding
x_transformed = Transformer(x)
prediction = MLP(x_transformed)

# Loss 1: Prediction loss (å¸Œæœ›x_transformedå˜åŒ–)
L_pred = CrossEntropy(prediction, label)
âˆ‚L_pred/âˆ‚Transformer_weights â†’ é¼“åŠ±æ”¹å˜embedding

# Loss 2: Reconstruction loss (å¸Œæœ›x_transformedä¸å˜)
L_recon = MSE(x_transformed, x)
âˆ‚L_recon/âˆ‚Transformer_weights â†’ æƒ©ç½šæ”¹å˜embedding

# æ€»loss
L_total = 0.6*L_pred + 0.3*L_recon
# æ¢¯åº¦æ–¹å‘ç›¸å,ç›¸äº’æŠµæ¶ˆ!
```

### Maskæœºåˆ¶æ€»ç»“ (ç”¨æˆ·ä¹‹å‰çš„é—®é¢˜)

1. **Maskä½ç½®**: åœ¨datasetåˆå§‹åŒ–æ—¶ç”Ÿæˆ,æ¯ä¸ªwindowå›ºå®šmaskä½ç½®
2. **Maskæ¯”ä¾‹**: ä»10%å¼€å§‹,æ¯ä¸ªepochå¢é•¿10% (add_level)
3. **Mask token**: vocabä¸­çš„index=4 (`<mask>`)
4. **MaskèŒƒå›´**: åªmaskåŸºå› å‹,ä¸mask metadata (POS/CHROMç­‰)

```python
# Dataset.__init__
self.window_masks = [generate_mask(len) for window in windows]
self.__mask_rate = [0.1, 0.2, 0.3, ..., 0.8]

# Dataset.__getitem__
mask = self.window_masks[window_idx]  # å›ºå®šä½ç½®
hap_masked = tokenize(hap_original, mask)  # æ›¿æ¢ä¸º<mask>

# add_level()æ¯ä¸ªepochè°ƒç”¨
self.__level = min(self.__level + 1, 7)  # 0â†’1â†’2... (10%â†’20%â†’30%...)
```

---

## ğŸ“ˆ æˆåŠŸæ ‡å‡†

### âœ… è®­ç»ƒæˆåŠŸçš„æ ‡å¿—

1. **LossæŒç»­ä¸‹é™**
   - ä¸åº”è¯¥åœ¨epoch 2å°±åœæ»
   - åº”è¯¥çœ‹åˆ°å¹³æ»‘çš„ä¸‹é™æ›²çº¿

2. **F1æŒç»­æå‡**
   - Train F1åº”è¯¥ä»epoch 2ç»§ç»­ä¸Šå‡
   - ä¸åº”è¯¥97.75%åå®Œå…¨ä¸åŠ¨

3. **éªŒè¯é›†æœ‰æ³¢åŠ¨**
   - Val F1ä¸åº”è¯¥16ä½å°æ•°å®Œå…¨ç›¸åŒ
   - åº”è¯¥çœ‹åˆ°Â±0.001-0.01çš„è‡ªç„¶æ³¢åŠ¨

4. **Rare F1æ”¹è¿›**
   - ç›®å‰Rare F1=95.1%ä½äºCommon F1=98.1%
   - ä¼˜åŒ–åRare F1å¯èƒ½æå‡åˆ°96-97%

### âš ï¸ ä»éœ€è­¦æƒ•çš„é—®é¢˜

1. **è¿‡æ‹Ÿåˆ**: å¦‚æœTrain F1>>Val F1,éœ€è¦è°ƒæ•´æ­£åˆ™åŒ–
2. **æ¬ æ‹Ÿåˆ**: å¦‚æœTrainå’ŒVal F1éƒ½å¾ˆä½,éœ€è¦å¢åŠ æ¨¡å‹å®¹é‡
3. **è®­ç»ƒå¤ªå¿«**: å¦‚æœlossä¸‹é™è¿‡å¿«,å¯èƒ½gammaè¿˜æ˜¯å¤ªå¤§

---

## ğŸ“ æ—¥å¿—ç¤ºä¾‹

### æ­£å¸¸è®­ç»ƒæ—¥å¿— (æœŸæœ›çœ‹åˆ°)

```
Epoch 1: Train Loss: 28.45, Train F1: 89.2%
  Val Loss: 26.32, Val F1: 90.5%
  Rare F1: 87.3%, Common F1: 91.8%

Epoch 2: Train Loss: 22.18, Train F1: 93.7%
  Val Loss: 21.56, Val F1: 94.1%
  Rare F1: 91.2%, Common F1: 95.4%

Epoch 3: Train Loss: 18.92, Train F1: 95.4%  â† ç»§ç»­ä¸Šå‡
  Val Loss: 18.67, Val F1: 95.8%            â† æœ‰å˜åŒ–
  Rare F1: 93.5%, Common F1: 96.9%          â† æŒç»­æ”¹è¿›
...
```

### é—®é¢˜è®­ç»ƒæ—¥å¿— (ä¸åº”è¯¥çœ‹åˆ°)

```
Epoch 1: Train Loss: 24.86, Train F1: 92.3%
Epoch 2: Train Loss: 14.90, Train F1: 97.76%
Epoch 3: Train Loss: 14.90, Train F1: 97.75%  â† åœæ»
Epoch 4: Train Loss: 14.90, Train F1: 97.75%  â† å®Œå…¨ä¸€æ ·
...
```

---

## ğŸ”„ åç»­ä¼˜åŒ–å»ºè®®

å¦‚æœä¼˜åŒ–ç‰ˆä»æœ‰é—®é¢˜,å¯ä»¥å°è¯•:

1. **è¿›ä¸€æ­¥é™ä½gamma**: 2.5 â†’ 2.0 â†’ 1.5
2. **è°ƒæ•´å­¦ä¹ ç‡**: 5e-5 â†’ 1e-4
3. **å‡å°‘warmup**: 10000 â†’ 5000
4. **æ•°æ®å¢å¼º**: å¢åŠ maskéšæœºæ€§
5. **æ­£åˆ™åŒ–**: æ·»åŠ dropout, weight decay

---

## ğŸ“š ç›¸å…³æ–‡ä»¶

- [train_with_val_optimized.py](src/train_with_val_optimized.py) - ä¼˜åŒ–ç‰ˆè®­ç»ƒå…¥å£
- [pretrain_with_val_optimized.py](src/main/pretrain_with_val_optimized.py) - ä¼˜åŒ–ç‰ˆTrainer
- [run_v13_optimized.sh](run_v13_optimized.sh) - è¿è¡Œè„šæœ¬
- [plot_metrics_csv.py](scripts/plot_metrics_csv.py) - å¯è§†åŒ–å·¥å…·

---

**åˆ›å»ºæ—¶é—´**: 2025-12-02
**é—®é¢˜**: è®­ç»ƒåœ¨epoch 2ååœæ»,éªŒè¯é›†æŒ‡æ ‡å®Œå…¨ä¸å˜
**æ ¹æœ¬åŸå› **: Focal gamma=5è¿‡é«˜ + recon lossæ¢¯åº¦å†²çª
**è§£å†³æ–¹æ¡ˆ**: gammaé™è‡³2.5 + ç§»é™¤recon loss + æé«˜å­¦ä¹ ç‡
