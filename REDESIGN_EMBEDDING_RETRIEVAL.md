# ç«¯åˆ°ç«¯Embeddingæ£€ç´¢é‡æ–°è®¾è®¡

## ğŸ¯ æ ¸å¿ƒæ€æƒ³

**å½“å‰é—®é¢˜**: RAGæ£€ç´¢raw tokens â†’ è¿‡BERTç¼–ç  â†’ Fusion
- å†…å­˜: æ¯ä¸ªbatchéƒ½è¦å¯¹retrieved sequencesè¿‡BERT
- æ•ˆç‡: é‡å¤ç¼–ç ç›¸åŒçš„reference sequences
- æ¬¡ä¼˜: æ£€ç´¢å‘ç”Ÿåœ¨token spaceè€Œélearned embedding space

**æ–°è®¾è®¡**: Query embedding â†’ æ£€ç´¢pre-encoded embeddings â†’ Fusion
- å†…å­˜: æ— éœ€é‡å¤è¿‡BERT,åªæ£€ç´¢embedding
- æ•ˆç‡: Reference sequencesé¢„ç¼–ç ä¸€æ¬¡
- ç«¯åˆ°ç«¯: æ£€ç´¢åœ¨embedding space,æ¢¯åº¦å¯ä»¥å›ä¼ 

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### é˜¶æ®µ1: é¢„ç¼–ç Reference Panel (åˆå§‹åŒ–æ—¶)

```python
class EmbeddingRAGDataset(TrainDataset):
    def _build_embedding_index(self, ref_vcf_path, pretrained_bert=None):
        """
        é¢„ç¼–ç æ‰€æœ‰reference sequencesä¸ºembeddings
        """
        print("Building embedding-based RAG index...")

        # åŠ è½½reference data
        ref_gt, ref_pos = self._load_ref_data(ref_vcf_path)

        # å¦‚æœæä¾›é¢„è®­ç»ƒBERT,ç”¨å®ƒç¼–ç 
        if pretrained_bert is None:
            # ä½¿ç”¨ç®€å•çš„å¯å­¦ä¹ embedding
            self.ref_encoder = nn.Embedding(vocab_size, dims)
        else:
            # ä½¿ç”¨é¢„è®­ç»ƒBERTçš„embeddingå±‚
            self.ref_encoder = pretrained_bert.embedding

        # é¢„ç¼–ç æ‰€æœ‰reference sequences
        self.ref_embeddings = {}

        with torch.no_grad():
            for w_idx in tqdm(range(self.window_count), desc="Encoding references"):
                window_slice = slice(
                    self.window.window_info[w_idx, 0],
                    self.window.window_info[w_idx, 1]
                )

                # è¯¥windowçš„æ‰€æœ‰reference haplotypes
                window_refs = ref_gt[window_slice]  # [L, num_samples*2]
                window_pos = ref_pos[window_slice]

                # Flatten to [num_haps, L]
                num_haps = window_refs.shape[1]
                ref_haps = window_refs.T  # [num_haps, L]

                # ç¼–ç ä¸ºembeddings: [num_haps, L, D]
                ref_emb = self.ref_encoder(
                    torch.LongTensor(ref_haps),
                    pos=torch.LongTensor(window_pos).unsqueeze(0).expand(num_haps, -1),
                    af=...,  # ä»freq_pathåŠ è½½
                    type_idx=...
                )

                # å­˜å‚¨åœ¨CPU (é¿å…å ç”¨GPUå†…å­˜)
                self.ref_embeddings[w_idx] = ref_emb.cpu()

                # æ„å»ºFAISS index (åœ¨embedding space)
                # Flatten embeddings: [num_haps, L*D]
                ref_emb_flat = ref_emb.reshape(num_haps, -1).cpu().numpy()

                index = faiss.IndexFlatL2(ref_emb_flat.shape[1])
                index.add(ref_emb_flat)
                self.embedding_indexes.append(index)

        print(f"âœ“ Built embedding index for {self.window_count} windows")
```

### é˜¶æ®µ2: è®­ç»ƒæ—¶æ£€ç´¢ (forward pass)

```python
def __getitem__(self, item):
    output = super().__getitem__(item)
    window_idx = item % self.window_count

    # è·å–queryçš„raw sequence
    query_seq = output['hap1_nomask']  # [L]

    # åœ¨collate_fnä¸­ä¼šç¼–ç ä¸ºembeddingå¹¶æ£€ç´¢
    output['window_idx'] = window_idx
    output['retrieve_embedding'] = True  # æ ‡è®°ä½¿ç”¨embeddingæ£€ç´¢

    return output
```

```python
def embedding_rag_collate_fn(batch_list, dataset):
    """
    æ–°çš„collateå‡½æ•°: åœ¨embedding spaceæ£€ç´¢
    """
    batch = default_collate(batch_list)
    B = len(batch_list)

    # Step 1: å¯¹query sequencesç¼–ç  (éœ€è¦è¿‡BERT embeddingå±‚)
    # æ³¨æ„: è¿™é‡Œåªè¿‡embeddingå±‚,ä¸è¿‡transformer!
    query_emb = dataset.query_encoder(
        batch['hap_seq'],
        batch['pos'],
        batch['af'],
        batch['type_idx']
    )  # [B, L, D]

    # Step 2: åœ¨embedding spaceæ£€ç´¢
    retrieved_embs = []

    for i in range(B):
        window_idx = batch['window_idx'][i]

        # Query embedding flatten: [L*D]
        query_flat = query_emb[i].reshape(-1).cpu().numpy()

        # FAISSæ£€ç´¢ (åœ¨embedding space)
        D, I = dataset.embedding_indexes[window_idx].search(
            query_flat.reshape(1, -1),
            k=1  # æ£€ç´¢top-1
        )

        # è·å–pre-encoded embedding
        retrieved_idx = I[0, 0]
        retrieved_emb = dataset.ref_embeddings[window_idx][retrieved_idx]  # [L, D]

        retrieved_embs.append(retrieved_emb)

    # Step 3: Stack retrieved embeddings
    batch['rag_h1_emb'] = torch.stack(retrieved_embs)  # [B, L, D]
    batch['rag_h2_emb'] = torch.stack(retrieved_embs)  # ç®€åŒ–: h1å’Œh2ç”¨ç›¸åŒ

    return batch
```

### é˜¶æ®µ3: æ¨¡å‹Forward (æ— éœ€è¿‡BERT)

```python
class BERTWithEmbeddingRAG(nn.Module):
    def forward(self, x):
        # è·å–input
        hap_seq = x['hap_seq']
        pos = x['pos']
        af = x['af']
        type_idx = x['type_idx']

        # Embedding
        h1 = self.embedding(hap_seq[:, 0], pos, af, type_idx)  # [B, L, D]
        h2 = self.embedding(hap_seq[:, 1], pos, af, type_idx)

        # è·å–pre-encoded RAG embeddings (æ¥è‡ªcollate_fn)
        rag_h1_emb = x.get('rag_h1_emb', None)  # [B, L, D]
        rag_h2_emb = x.get('rag_h2_emb', None)

        if rag_h1_emb is not None:
            # å…³é”®: RAG embeddingså·²ç»é¢„ç¼–ç ,æ— éœ€è¿‡BERT!
            # ç›´æ¥Fusion
            h1_fused = self.fusion_module(h1, rag_h1_emb.to(h1.device))
            h2_fused = self.fusion_module(h2, rag_h2_emb.to(h2.device))
        else:
            h1_fused = h1
            h2_fused = h2

        # è¿‡Transformer (åªè¿‡ä¸€æ¬¡!)
        for transformer in self.transformer_blocks:
            h1_fused = transformer(h1_fused)
            h2_fused = transformer(h2_fused)

        # Prediction heads
        hap_1_pred = self.hap_classifier(h1_fused)
        hap_2_pred = self.hap_classifier(h2_fused)
        gt_pred = self.gt_classifier(torch.cat([h1_fused, h2_fused], dim=-1))

        return hap_1_pred, hap_2_pred, gt_pred, h1_fused, h2_fused
```

---

## ğŸ“Š å†…å­˜å’Œé€Ÿåº¦å¯¹æ¯”

### å½“å‰RAG (V17)

```
å†…å­˜æ¶ˆè€—:
- Query sequencesè¿‡BERT: 9 GB (batch=16)
- Retrieved sequencesè¿‡BERT: 9 GB
- Total: 18 GB forward

é€Ÿåº¦:
- Query encoding: 100 ms
- RAG encoding: 100 ms
- FAISS search: 5 ms
- Fusion: 10 ms
- Total: 215 ms/batch
```

### Embedding RAG (æ–°è®¾è®¡)

```
é¢„è®¡ç®— (åˆå§‹åŒ–æ—¶,ä¸€æ¬¡æ€§):
- Reference encoding: æ‰€æœ‰windowsä¸€æ¬¡æ€§ç¼–ç 
- æ—¶é—´: ~10 minutes
- å­˜å‚¨: ~500 MB (CPUå†…å­˜)

è®­ç»ƒæ—¶å†…å­˜æ¶ˆè€—:
- Query sequencesè¿‡embedding: 0.5 GB (åªembeddingå±‚)
- FAISSæ£€ç´¢: 0.1 GB
- Retrieved embeddings: 0.5 GB (å·²é¢„ç¼–ç )
- Fusion: 0.5 GB
- Transformer (åªè¿‡ä¸€æ¬¡): 9 GB
- Total: 10.6 GB forward (vs 18 GB)

é€Ÿåº¦:
- Query embedding: 10 ms (åªembeddingå±‚)
- FAISS search: 5 ms
- Fusion: 10 ms
- Transformer: 100 ms
- Total: 125 ms/batch

æ”¶ç›Š:
- å†…å­˜: 18 GB â†’ 10.6 GB (å‡å°‘41%)
- é€Ÿåº¦: 215 ms â†’ 125 ms (å¿«1.7x)
- Batch size: 16 â†’ 32+ (2å€)
```

---

## ğŸ“ ç«¯åˆ°ç«¯å¯å­¦ä¹ æ€§

### æ–¹æ¡ˆA: å›ºå®šPre-encoded Embeddings

**ä¼˜ç‚¹**: ç®€å•,ç«‹å³å¯ç”¨
**ç¼ºç‚¹**: Reference embeddingsä¸ä¼šéšè®­ç»ƒæ›´æ–°

### æ–¹æ¡ˆB: åŠ¨æ€æ›´æ–° (çœŸæ­£ç«¯åˆ°ç«¯)

```python
class LearnableEmbeddingRAG(nn.Module):
    def __init__(self):
        # Reference encoder (å¯å­¦ä¹ )
        self.ref_encoder = BERTEmbedding(...)

        # Query encoder (ä¸main modelå…±äº«)
        self.query_encoder = self.ref_encoder  # å…±äº«æƒé‡

    def refresh_reference_embeddings(self, dataset):
        """
        è®­ç»ƒä¸­å®šæœŸåˆ·æ–°reference embeddings
        """
        with torch.no_grad():
            for w_idx in range(dataset.window_count):
                ref_seqs = dataset.ref_sequences[w_idx]

                # ç”¨æ›´æ–°åçš„encoderé‡æ–°ç¼–ç 
                ref_emb = self.ref_encoder(ref_seqs, ...)
                dataset.ref_embeddings[w_idx] = ref_emb.cpu()

                # é‡å»ºFAISS index
                ref_emb_flat = ref_emb.reshape(num_haps, -1).numpy()
                dataset.embedding_indexes[w_idx].reset()
                dataset.embedding_indexes[w_idx].add(ref_emb_flat)
```

**è®­ç»ƒæµç¨‹**:
```python
for epoch in range(epochs):
    for batch in dataloader:
        # Normal training
        loss.backward()
        optimizer.step()

    # æ¯ä¸ªepochç»“æŸååˆ·æ–°reference embeddings
    model.refresh_reference_embeddings(train_dataset)
    print(f"âœ“ Refreshed reference embeddings for epoch {epoch+1}")
```

---

## ğŸš€ å®æ–½è·¯çº¿å›¾

### Phase 1: åŸºç¡€ç‰ˆ (2-3å°æ—¶)

1. âœ… ä¿®æ”¹ `rag_train_dataset.py`:
   - æ·»åŠ  `_build_embedding_index()`
   - é¢„ç¼–ç reference sequences
   - æ„å»ºembedding-based FAISS index

2. âœ… ä¿®æ”¹ `collate_fn`:
   - Queryç¼–ç åªè¿‡embeddingå±‚
   - FAISSæ£€ç´¢åœ¨embedding space
   - è¿”å›pre-encoded embeddings

3. âœ… ä¿®æ”¹ `bert.py`:
   - Forwardæ¥æ”¶pre-encoded RAG embeddings
   - è·³è¿‡RAGçš„transformer encoding
   - ç›´æ¥fusion

**é¢„æœŸæ•ˆæœ**:
- å†…å­˜: 18 GB â†’ 10.6 GB
- Batch size: 16 â†’ 32
- é€Ÿåº¦: 1.7x faster

### Phase 2: ç«¯åˆ°ç«¯å¯å­¦ä¹  (4-5å°æ—¶)

4. âœ… å®ç° `refresh_reference_embeddings()`
5. âœ… è®­ç»ƒå¾ªç¯ä¸­å®šæœŸåˆ·æ–°
6. âœ… æ¢¯åº¦å›ä¼ åˆ°reference encoder

**é¢„æœŸæ•ˆæœ**:
- Reference embeddingséšè®­ç»ƒä¼˜åŒ–
- æ£€ç´¢è´¨é‡æå‡
- F1å¯èƒ½+0.5-1%

### Phase 3: é«˜çº§ä¼˜åŒ– (1-2å¤©)

7. âœ… å¤šGPUå¹¶è¡Œé¢„ç¼–ç 
8. âœ… Approximate nearest neighbor (æ›´å¿«æ£€ç´¢)
9. âœ… Learned similarity metric (æ›¿ä»£L2è·ç¦»)
10. âœ… Hard negative mining

---

## ğŸ’¡ ä¸ºä»€ä¹ˆè¿™æ˜¯æœ€ä¼˜æ–¹æ¡ˆ

### å¯¹æ¯”å…¶ä»–æ–¹æ¡ˆ

| æ–¹æ¡ˆ | å†…å­˜ | é€Ÿåº¦ | æ¨¡å‹å®¹é‡ | å¯å­¦ä¹ æ€§ |
|------|------|------|---------|---------|
| V13 (å°æ¨¡å‹æ— RAG) | 6 GB | 1x | 2.1M | âœ… |
| V17 (ä¸­æ¨¡å‹+RAG) | 18 GB | 0.25x | 8M | âœ… |
| Embedding RAG | 10.6 GB | 1.7x | 8M+ | âœ… |

### æ ¸å¿ƒä¼˜åŠ¿

1. **å†…å­˜é«˜æ•ˆ**:
   - Referenceåªç¼–ç ä¸€æ¬¡ (vs æ¯batchç¼–ç )
   - æ£€ç´¢embeddingè€Œéraw sequences

2. **é€Ÿåº¦å¿«**:
   - æ— éœ€é‡å¤è¿‡BERT
   - FAISSæ£€ç´¢æå¿« (<5ms)

3. **ç«¯åˆ°ç«¯å¯å­¦ä¹ **:
   - æ¢¯åº¦å¯ä»¥å›ä¼ åˆ°encoder
   - Reference embeddingså¯ä»¥ä¼˜åŒ–

4. **å¯æ‰©å±•**:
   - æ”¯æŒæ›´å¤§reference panel
   - æ”¯æŒå¤šä¸ªretrieved sequences (K>1)

---

## ğŸ¯ ç«‹å³è¡ŒåŠ¨è®¡åˆ’

### é€‰é¡¹A: å¿«é€ŸéªŒè¯ (æ¨èå…ˆåš)

```bash
# è¿è¡ŒV17éªŒè¯æ¨¡å‹èƒ½å¦çªç ´97.75%
bash run_v17_extreme_memory_fix.sh

# å¦‚æœV17ä»ç„¶åœæ»åœ¨97.75%,è¯´æ˜8Må‚æ•°è¿˜ä¸å¤Ÿ
# é‚£ä¹ˆå¿…é¡»å®æ–½Embedding RAGæ‰èƒ½ç”¨æ›´å¤§æ¨¡å‹
```

### é€‰é¡¹B: å®æ–½Embedding RAG (æ ¹æœ¬è§£å†³)

æˆ‘å¯ä»¥å¸®ä½ å®ç°Phase 1 (åŸºç¡€ç‰ˆ):
1. ä¿®æ”¹datasetä»£ç 
2. ä¿®æ”¹modelä»£ç 
3. åˆ›å»ºæ–°çš„training script

**é¢„è®¡å·¥ä½œé‡**: 2-3å°æ—¶ç¼–ç  + 1å°æ—¶æµ‹è¯•
**æ”¶ç›Š**:
- Batch size 16 â†’ 48
- æ¨¡å‹å¯ä»¥ç”¨æ›´å¤§ (dims=256, layers=12)
- é€Ÿåº¦å¿«1.7x

---

## ğŸ“ æ€»ç»“

**å½“å‰V17**: 8Må‚æ•°, batch=16, è®­ç»ƒæ…¢4å€, å†…å­˜18GB
- ä¸æ˜¯é•¿ä¹…ä¹‹è®¡
- æœ‰æ•ˆæ•ˆç‡å‡ ä¹æ²¡æå‡

**Embedding RAG**: åŒæ ·8Må‚æ•°, batch=48, è®­ç»ƒå¿«1.7x, å†…å­˜10.6GB
- æ ¹æœ¬æ€§è§£å†³æ–¹æ¡ˆ
- å¯ä»¥æ”¯æŒæ›´å¤§æ¨¡å‹ (dims=256+)
- ç«¯åˆ°ç«¯å¯å­¦ä¹ 

**å»ºè®®**:
1. å…ˆè·‘V17,çœ‹8Må‚æ•°æ˜¯å¦å¤Ÿ
2. å¦‚æœä¸å¤Ÿ,ç«‹å³å®æ–½Embedding RAG
3. é•¿æœŸç”¨Embedding RAG + å¤§æ¨¡å‹ (dims=256, layers=12)

è¦æˆ‘å¸®ä½ å®ç°Embedding RAGå—?
