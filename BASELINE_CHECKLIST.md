# âœ… Baselineè®­ç»ƒæ£€æŸ¥æ¸…å•

## ğŸ¯ è®­ç»ƒå‰æ£€æŸ¥

### ç¯å¢ƒæ£€æŸ¥
```bash
# 1. ç¡®è®¤åœ¨æ­£ç¡®ç›®å½•
pwd
# åº”è¯¥è¾“å‡º: /cpfs01/.../00_RAG-SNVBERT-packup

# 2. æ£€æŸ¥æ•°æ®æ–‡ä»¶
ls -lh data/train_val_split/
# åº”è¯¥çœ‹åˆ°:
#   train_split.h5
#   train_panel.txt
#   val_split.h5
#   val_panel.txt

# 3. æ£€æŸ¥GPUå¯ç”¨
nvidia-smi
# ç¡®ä¿è‡³å°‘ä¸€å—GPUç©ºé—²

# 4. åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p logs/baseline_gamma5_recon30
ls -ld logs/baseline_gamma5_recon30/
```

### è„šæœ¬æ£€æŸ¥
```bash
# 5. ç¡®è®¤è®­ç»ƒè„šæœ¬å­˜åœ¨
ls -lh run_v12_split_val_with_log.sh
chmod +x run_v12_split_val_with_log.sh

# 6. å¿«é€Ÿæ£€æŸ¥è„šæœ¬å†…å®¹
head -20 run_v12_split_val_with_log.sh
# åº”è¯¥çœ‹åˆ° LOG_DIR="logs/baseline_gamma5_recon30"
```

---

## ğŸš€ å¯åŠ¨è®­ç»ƒ

### ç»ˆç«¯1: è¿è¡Œè®­ç»ƒ
```bash
bash run_v12_split_val_with_log.sh
```

**é¢„æœŸåˆå§‹è¾“å‡º**:
```
================================================
Starting training with logging
================================================
Log directory: logs/baseline_gamma5_recon30
Log file: logs/baseline_gamma5_recon30/training_20250101_120534.log
================================================

============================================================
Loading Data...
============================================================
âœ“ Panel loaded
Initializing Vocab...
âœ“ Vocab size: 9

Loading Training Dataset...
â–£ å¼€å§‹æ„å»ºFAISSç´¢å¼•
...
```

### ç»ˆç«¯2: ç›‘æ§è®­ç»ƒ (å¯é€‰)
```bash
# ç­‰å¾…ç¬¬ä¸€ä¸ªæ—¥å¿—æ–‡ä»¶å‡ºç° (çº¦1-2åˆ†é’Ÿ)
ls -lh logs/baseline_gamma5_recon30/

# å®æ—¶æŸ¥çœ‹æ—¥å¿—
tail -f logs/baseline_gamma5_recon30/latest.log
```

---

## ğŸ“Š ç¬¬ä¸€ä¸ªEpochæ£€æŸ¥ (~15-20åˆ†é’Ÿå)

### æ£€æŸ¥ç‚¹1: è®­ç»ƒæ˜¯å¦æ­£å¸¸å¯åŠ¨

```bash
# æŸ¥çœ‹æœ€æ–°æ—¥å¿—
tail -50 logs/baseline_gamma5_recon30/latest.log
```

**å¥åº·ä¿¡å·**: åº”è¯¥çœ‹åˆ°ç±»ä¼¼
```
EP_Train:0:  15%|â–ˆâ–ˆâ–ˆâ–Œ              | 645/4305 [02:15<13:02, 4.68it/s]
```

**é—®é¢˜ä¿¡å·**:
- âŒ æ²¡æœ‰è¿›åº¦æ¡æ›´æ–° â†’ è®­ç»ƒå¡ä½
- âŒ å‡ºç°ERROR/Exception â†’ ä»£ç é”™è¯¯
- âŒ NaN/Inf â†’ æ•°å€¼ä¸ç¨³å®š

### æ£€æŸ¥ç‚¹2: ç¬¬ä¸€ä¸ªEpoch Summary

```bash
# ç­‰å¾…ç¬¬ä¸€ä¸ªepochå®Œæˆ (~15-20åˆ†é’Ÿ)
# æŸ¥çœ‹summary
grep 'Epoch 1.*Summary' -A 15 logs/baseline_gamma5_recon30/latest.log
```

**é¢„æœŸè¾“å‡º**:
```
============================================================
Epoch 1 TRAIN Summary
============================================================
Avg Loss:      0.6234  â† åº”è¯¥åœ¨0.5-0.8ä¹‹é—´
Avg Accuracy:  0.7123  â† åº”è¯¥>0.5

Haplotype Metrics:
  - F1:        0.6823  â† ç¬¬ä¸€ä¸ªepoché€šå¸¸0.6-0.75
  - Precision: 0.6945
  - Recall:    0.6705

============================================================
Epoch 1 VAL Summary
============================================================
Avg Loss:      0.6512
Avg Accuracy:  0.6987

Haplotype Metrics:
  - F1:        0.6512  â† Val F1é€šå¸¸ç•¥ä½äºTrain
  - Precision: 0.6634
  - Recall:    0.6395
```

**å¥åº·åˆ¤æ–­**:
- âœ… Lossåœ¨åˆç†èŒƒå›´ (0.5-0.8)
- âœ… Accuracy > 0.5 (å¦åˆ™æ¯”éšæœºçŒœæµ‹è¿˜å·®)
- âœ… Train F1 > Val F1 (æ­£å¸¸)
- âœ… Train F1 - Val F1 < 0.1 (æ²¡æœ‰ä¸¥é‡è¿‡æ‹Ÿåˆ)

**é—®é¢˜ä¿¡å·**:
- âŒ Loss > 1.5 â†’ å¯èƒ½å­¦ä¹ ç‡è¿‡å¤§
- âŒ Loss < 0.1 â†’ å¯èƒ½æ•°æ®/ä»£ç é—®é¢˜
- âŒ Accuracy < 0.5 â†’ æ¨¡å‹æ²¡æœ‰å­¦ä¹ 
- âŒ Val F1 > Train F1 â†’ å¼‚å¸¸ (æ•°æ®æ³„æ¼?)

---

## ğŸ” å‰5ä¸ªEpochè§‚å¯Ÿ (~1.5å°æ—¶å)

### æ£€æŸ¥ç‚¹3: F1è¶‹åŠ¿

```bash
# æå–å‰5ä¸ªepochçš„val F1
grep 'VAL Summary' -A 10 logs/baseline_gamma5_recon30/latest.log | \
    grep 'F1:' | head -5
```

**å¥åº·ä¿¡å·** (ç¨³å®šå¢é•¿):
```
Epoch 1: F1: 0.6512
Epoch 2: F1: 0.6734  â† +0.0222
Epoch 3: F1: 0.6912  â† +0.0178
Epoch 4: F1: 0.7023  â† +0.0111
Epoch 5: F1: 0.7145  â† +0.0122
```
åˆ¤æ–­: âœ… æ¯ä¸ªepochç¨³å®šæå‡

**é—®é¢˜ä¿¡å·** (éœ‡è¡):
```
Epoch 1: F1: 0.6512
Epoch 2: F1: 0.6234  â† ä¸‹é™!
Epoch 3: F1: 0.6756  â† å¤§å¹…æ³¢åŠ¨
Epoch 4: 0.6423  â† ç»§ç»­æ³¢åŠ¨
Epoch 5: F1: 0.6834
```
åˆ¤æ–­: âš ï¸ è®­ç»ƒä¸ç¨³å®š (å¯èƒ½æ˜¯gamma=5çš„é—®é¢˜)

### æ£€æŸ¥ç‚¹4: è¿‡æ‹Ÿåˆæ£€æŸ¥

```bash
# å¯¹æ¯”trainå’Œval F1
grep -E 'Epoch [1-5] (TRAIN|VAL) Summary' -A 5 logs/baseline_gamma5_recon30/latest.log | \
    grep 'F1:' | paste - -
```

**é¢„æœŸè¾“å‡º**:
```
Epoch 1 TRAIN F1: 0.7045    Epoch 1 VAL F1: 0.6512    Gap: 0.0533
Epoch 2 TRAIN F1: 0.7234    Epoch 2 VAL F1: 0.6734    Gap: 0.0500
Epoch 3 TRAIN F1: 0.7412    Epoch 3 VAL F1: 0.6912    Gap: 0.0500
Epoch 4 TRAIN F1: 0.7545    Epoch 4 VAL F1: 0.7023    Gap: 0.0522
Epoch 5 TRAIN F1: 0.7678    Epoch 5 VAL F1: 0.7145    Gap: 0.0533
```

**å¥åº·åˆ¤æ–­**:
- âœ… Gapç¨³å®šåœ¨0.03-0.06 â†’ è½»å¾®è¿‡æ‹Ÿåˆ,å¯æ¥å—
- âœ… Gapæ²¡æœ‰æ˜æ˜¾å¢å¤§ â†’ æœªæ¶åŒ–

**é—®é¢˜ä¿¡å·**:
- âš ï¸ Gap > 0.10 â†’ æ˜æ˜¾è¿‡æ‹Ÿåˆ
- ğŸ”´ GapæŒç»­å¢å¤§ (0.05 â†’ 0.10 â†’ 0.15) â†’ è¿‡æ‹ŸåˆåŠ å‰§

### æ£€æŸ¥ç‚¹5: ç”Ÿæˆä¸­æœŸåˆ†æ

```bash
# 5ä¸ªepochåç”Ÿæˆåˆ†æ
python scripts/analyze_training_log.py \
    logs/baseline_gamma5_recon30/latest.log \
    --output logs/analysis/

# æŸ¥çœ‹ç”Ÿæˆçš„å›¾è¡¨
ls -lh logs/analysis/*.png
```

**æŸ¥çœ‹å›¾è¡¨** (å¦‚æœæœ‰å›¾å½¢ç•Œé¢):
```bash
# æŸ¥çœ‹F1/Lossæ›²çº¿
xdg-open logs/analysis/*_analysis.png  # Linux
# æˆ–
open logs/analysis/*_analysis.png      # macOS
```

---

## ğŸ¯ å†³ç­–ç‚¹ (5ä¸ªEpochå)

### åœºæ™¯A: ä¸€åˆ‡æ­£å¸¸ âœ…

**ä¿¡å·**:
- Val F1ç¨³å®šå¢é•¿
- Gap < 0.08
- Losså¹³æ»‘ä¸‹é™

**è¡ŒåŠ¨**: ç»§ç»­è®­ç»ƒåˆ°early stoppingæˆ–20 epochs

```bash
# ç»§ç»­ç›‘æ§
tail -f logs/baseline_gamma5_recon30/latest.log | \
    grep 'Summary' -A 10
```

---

### åœºæ™¯B: è®­ç»ƒä¸ç¨³å®š âš ï¸

**ä¿¡å·**:
- Val F1éœ‡è¡
- Lossæ³¢åŠ¨å¤§
- Gapä¸ç¨³å®š

**åˆ†æ**:
```bash
# æŸ¥çœ‹lossæ›²çº¿
grep 'Avg Loss:' logs/baseline_gamma5_recon30/latest.log | head -10
```

**è¡ŒåŠ¨**:
1. ç»§ç»­è§‚å¯Ÿ2-3ä¸ªepochs
2. å¦‚æœæŒç»­éœ‡è¡ â†’ è€ƒè™‘æå‰åœæ­¢å¹¶ä¼˜åŒ–
3. è®°å½•é—®é¢˜ â†’ ä¸ºä¼˜åŒ–ç‰ˆæœ¬æä¾›å¯¹æ¯”

---

### åœºæ™¯C: ä¸¥é‡è¿‡æ‹Ÿåˆ ğŸ”´

**ä¿¡å·**:
- Train F1 - Val F1 > 0.15
- Val F1ä¸å¢é•¿,Train F1æŒç»­å¢é•¿

**ç¤ºä¾‹**:
```
Epoch 3 TRAIN: 0.7856, VAL: 0.6234  Gap=0.1622
Epoch 4 TRAIN: 0.8123, VAL: 0.6189  Gap=0.1934  â† æ¶åŒ–
Epoch 5 TRAIN: 0.8345, VAL: 0.6156  Gap=0.2189  â† ç»§ç»­æ¶åŒ–
```

**è¡ŒåŠ¨**:
1. æå‰åœæ­¢è®­ç»ƒ (å·²ç»æœ‰baselineæ•°æ®)
2. ç«‹å³åº”ç”¨ä¼˜åŒ– (gamma=2.5, no recon)
3. å¯¹æ¯”ä¼˜åŒ–æ•ˆæœ

---

## ğŸ“ è®­ç»ƒå®Œæˆååˆ†æ

### å®Œæ•´åˆ†æ

```bash
# 1. ç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Š
python scripts/analyze_training_log.py \
    logs/baseline_gamma5_recon30/latest.log \
    --output logs/analysis/

# 2. æŸ¥çœ‹å…³é”®æŒ‡æ ‡
cat << 'EOF'
============================================================
Baseline Training Summary
============================================================
EOF

# æœ€ä½³validation F1
echo "Best Val F1:"
grep 'New best f1:' logs/baseline_gamma5_recon30/latest.log | tail -1

# æ”¶æ•›é€Ÿåº¦
echo -e "\nConvergence Speed:"
grep 'VAL Summary' -A 10 logs/baseline_gamma5_recon30/latest.log | \
    grep 'F1:' | \
    awk '{print NR, $3}' | \
    awk '$2 > 0.7 {print "Epochs to F1>0.7:", NR; exit}'

# æ˜¯å¦è§¦å‘early stopping
echo -e "\nEarly Stopping:"
grep 'Early stopping' logs/baseline_gamma5_recon30/latest.log || \
    echo "Completed all epochs (no early stopping)"

# æ€»epochs
echo -e "\nTotal Epochs Trained:"
grep 'Epoch.*Summary' logs/baseline_gamma5_recon30/latest.log | \
    tail -1 | grep -oP 'Epoch \K\d+'
```

---

## ğŸ—‚ï¸ ä¿å­˜Baselineç»“æœ

```bash
# åˆ›å»ºbaselineæ€»ç»“æ–‡ä»¶
cat > logs/baseline_gamma5_recon30/SUMMARY.txt << 'EOF'
Baseline Training Configuration
================================

Model Config:
- Focal gamma: 5
- Recon loss weight: 30% (0.15+0.15)
- RAG K: 1
- Batch size: 64 (train), 128 (val)

Training Config:
- Epochs: 20
- Patience: 5
- Learning rate: 1e-5

Results:
- Best Val F1: [FILL]
- @Epoch: [FILL]
- Final Val F1: [FILL]
- Overfitting Gap: [FILL]
- Epochs to F1>0.7: [FILL]
- Training time: [FILL]

Issues Observed:
- [ ] Val F1éœ‡è¡
- [ ] ä¸¥é‡è¿‡æ‹Ÿåˆ
- [ ] Lossä¸ç¨³å®š
- [ ] æ”¶æ•›æ…¢

Next Steps:
- [ ] åº”ç”¨ä¼˜åŒ– (gamma=2.5, no recon)
- [ ] å¯¹æ¯”åˆ†æ
EOF

# æ‰‹åŠ¨å¡«å†™ç»“æœ
nano logs/baseline_gamma5_recon30/SUMMARY.txt
```

---

## ğŸš€ å‡†å¤‡ä¼˜åŒ–ç‰ˆæœ¬

### å¦‚æœå†³å®šä¼˜åŒ–

```bash
# 1. å¤‡ä»½å½“å‰ä»£ç 
cp src/main/pretrain_with_val.py src/main/pretrain_with_val.py.baseline

# 2. åˆ›å»ºä¼˜åŒ–ç‰ˆæœ¬çš„issue tracking
cat > logs/OPTIMIZATION_PLAN.md << 'EOF'
# Optimization Plan

## Baseline Issues
- [ ] Issue 1: ...
- [ ] Issue 2: ...

## Optimization Config
- Focal gamma: 5 â†’ 2.5
- Recon loss: 30% â†’ 0%

## Expected Improvements
- Val F1: +5-10%
- Convergence: 2-3x faster
- Stability: Lossæ›²çº¿æ›´å¹³æ»‘

## Timeline
- Day 1: Baselineå®Œæˆ
- Day 2: ä¿®æ”¹ä»£ç ,å¯åŠ¨ä¼˜åŒ–è®­ç»ƒ
- Day 3: å¯¹æ¯”åˆ†æ
EOF
```

---

## ğŸ“ é‡åˆ°é—®é¢˜æ£€æŸ¥

### é—®é¢˜: è®­ç»ƒå¡ä½ä¸åŠ¨

```bash
# æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜æ´»
ps aux | grep python | grep train_with_val

# æ£€æŸ¥GPUä½¿ç”¨
nvidia-smi

# æŸ¥çœ‹æœ€åå‡ è¡Œæ—¥å¿—
tail -20 logs/baseline_gamma5_recon30/latest.log
```

### é—®é¢˜: æ˜¾å­˜ä¸è¶³ (OOM)

```bash
# æŸ¥çœ‹é”™è¯¯
grep -i 'out of memory\|oom' logs/baseline_gamma5_recon30/latest.log

# è§£å†³: é™ä½batch size
# ç¼–è¾‘ run_v12_split_val_with_log.sh
--train_batch_size 32
--val_batch_size 64
```

### é—®é¢˜: æ—¥å¿—æ–‡ä»¶æ²¡æœ‰åˆ›å»º

```bash
# æ£€æŸ¥ç›®å½•æƒé™
ls -ld logs/baseline_gamma5_recon30/

# æ‰‹åŠ¨åˆ›å»º
mkdir -p logs/baseline_gamma5_recon30

# æ£€æŸ¥teeå‘½ä»¤
which tee
```

---

## âœ… æœ€ç»ˆæ£€æŸ¥æ¸…å•

### è®­ç»ƒå‰
- [ ] GPUå¯ç”¨ (`nvidia-smi`)
- [ ] æ•°æ®æ–‡ä»¶å­˜åœ¨ (`ls data/train_val_split/`)
- [ ] æ—¥å¿—ç›®å½•åˆ›å»º (`mkdir -p logs/baseline_gamma5_recon30`)
- [ ] è„šæœ¬å¯æ‰§è¡Œ (`chmod +x run_v12_split_val_with_log.sh`)

### è®­ç»ƒä¸­ (æ¯1-2å°æ—¶)
- [ ] æ£€æŸ¥è®­ç»ƒè¿›åº¦ (`tail logs/baseline_gamma5_recon30/latest.log`)
- [ ] éªŒè¯F1è¶‹åŠ¿ (`grep 'VAL.*F1:'`)
- [ ] ç›‘æ§è¿‡æ‹Ÿåˆ (`å¯¹æ¯”trainå’Œval F1`)

### 5ä¸ªEpochå
- [ ] ç”Ÿæˆä¸­æœŸåˆ†æ (`python scripts/analyze_training_log.py`)
- [ ] å†³å®šç»§ç»­æˆ–ä¼˜åŒ–

### è®­ç»ƒå®Œæˆå
- [ ] å®Œæ•´åˆ†æ (`analyze_training_log.py --output`)
- [ ] å¡«å†™SUMMARY.txt
- [ ] ä¿å­˜baseline checkpoint
- [ ] å‡†å¤‡ä¼˜åŒ–ç‰ˆæœ¬

---

**ç°åœ¨å¼€å§‹baselineè®­ç»ƒ!** ğŸš€

```bash
bash run_v12_split_val_with_log.sh
```
