# ğŸ“‹ V18 Embedding RAG æ¨ç†æŒ‡å—

## ğŸ“¦ æ–‡ä»¶æ¸…å•

V18 ä¸“ç”¨æ¨ç†ç³»ç»ŸåŒ…å«ä»¥ä¸‹æ–°æ–‡ä»¶ï¼š

1. **æ•°æ®é›†ç±»**: `src/dataset/embedding_rag_infer_dataset.py`
   - `EmbeddingRAGInferDataset`: V18 ä¸“ç”¨æ¨ç†æ•°æ®é›†
   - å®ç° Imputation Masking å’Œå¯¹ç§° Masking

2. **æ¨ç†è„šæœ¬**: `src/infer_embedding_rag.py`
   - V18 æ¨ç†ä¸»ç¨‹åº
   - åŠ è½½æ¨¡å‹ã€æ‰§è¡Œæ¨ç†ã€ç”Ÿæˆ VCF

3. **è¿è¡Œè„šæœ¬**: `run_infer_embedding_rag.sh`
   - ä¸€é”®å¯åŠ¨æ¨ç†
   - é…ç½®å‚æ•°å’Œè·¯å¾„

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ­¥éª¤ 1: æ‹‰å–æœ€æ–°ä»£ç 

```bash
cd /cpfs01/projects-HDD/humPOG_HDD/wbn_24110700074/RAG_Version/VCF-Bert/00_RAG-SNVBERT-packup

git pull origin main
```

**é¢„æœŸè¾“å‡º**ï¼š
```
Updating e103a24..xxxxxxx
Fast-forward
 src/dataset/embedding_rag_infer_dataset.py | 450 ++++++++++++++++++++
 src/infer_embedding_rag.py                 | 350 +++++++++++++++
 run_infer_embedding_rag.sh                 | 120 ++++++
 V18_INFERENCE_GUIDE.md                     | 500 ++++++++++++++++++++++
 4 files changed, 1420 insertions(+)
```

### æ­¥éª¤ 2: éªŒè¯æ–‡ä»¶

```bash
# æ£€æŸ¥æ•°æ®é›†ç±»
ls -lh src/dataset/embedding_rag_infer_dataset.py

# æ£€æŸ¥æ¨ç†è„šæœ¬
ls -lh src/infer_embedding_rag.py

# æ£€æŸ¥è¿è¡Œè„šæœ¬
ls -lh run_infer_embedding_rag.sh
```

### æ­¥éª¤ 3: é…ç½®æ¨ç†å‚æ•°

ç¼–è¾‘ `run_infer_embedding_rag.sh`ï¼Œä¿®æ”¹ä»¥ä¸‹å…³é”®å‚æ•°ï¼š

```bash
vim run_infer_embedding_rag.sh
```

**å¿…é¡»ä¿®æ”¹çš„å‚æ•°**ï¼š

```bash
# 1. æ¨¡å‹ Checkpoint (è®­ç»ƒå¥½çš„æœ€ä½³æ¨¡å‹)
CHECK_POINT="/path/to/your/rag_bert.model.ep11"

# 2. æ¨¡å‹æ¶æ„å‚æ•° (å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´!)
DIMS=384         # Hidden dimension
LAYERS=6         # Number of layers
HEADS=8          # Attention heads

# 3. Target Dataset (å¾…å¡«è¡¥çš„æ•°æ®)
TARGET_DATASET="/path/to/your/target/data.h5"
TARGET_PANEL="/path/to/your/target/panel.txt"

# 4. Reference Panel (ç”¨äºæ„å»º FAISS ç´¢å¼•)
REF_PANEL="/path/to/train_split.h5"
REF_PANEL_INFO="/path/to/train_panel.txt"

# 5. è¾“å‡ºè·¯å¾„
OUTPUT_DIR="/path/to/output/directory"
```

### æ­¥éª¤ 4: å¯åŠ¨æ¨ç†

```bash
# ç»™è„šæœ¬æ‰§è¡Œæƒé™
chmod +x run_infer_embedding_rag.sh

# å¯åŠ¨æ¨ç†
bash run_infer_embedding_rag.sh
```

---

## ğŸ“Š æ¨ç†æµç¨‹è¯¦è§£

### æ ¸å¿ƒé€»è¾‘

V18 æ¨ç†ç³»ç»ŸåŸºäº **Imputation Masking** å’Œ **å¯¹ç§° Masking**ï¼š

```
Step 1: è®¡ç®— Imputation Mask
  Mask_Positions = All_Reference_Positions - Target_Known_Positions
  - Mask=1: éœ€è¦å¡«è¡¥çš„ä½ç½®
  - Mask=0: å·²çŸ¥ä½ç½®ï¼ˆä½œä¸º Contextï¼‰

Step 2: å¯¹ç§° Masking
  - Query (Target): åœ¨ Mask_Positions å¤„è®¾ä¸º [MASK]
  - Reference (Key): åœ¨ç›¸åŒçš„ Mask_Positions å¤„ä¹Ÿè®¾ä¸º [MASK]
  åŸå› : å¦‚æœ Reference æ˜¯å®Œæ•´çš„è€Œ Query æ˜¯æ®‹ç¼ºçš„ï¼Œ
       Embedding è·ç¦»ä¼šè¿‡å¤§å¯¼è‡´æ£€ç´¢å¤±æ•ˆ

Step 3: æ„å»ºç´¢å¼•
  - Key (ç”¨äºæ£€ç´¢): Masked Reference Embeddings
  - Value (ç”¨äºç”Ÿæˆ): Complete Reference Tokens

Step 4: æ¨ç†
  - ç¼–ç  Query (Masked)
  - FAISS æ£€ç´¢ (Masked Query vs Masked Reference)
  - æŒ‰éœ€ç¼–ç  Complete Reference (æ£€ç´¢åˆ°çš„)
  - æ¨¡å‹å‰å‘ (Query + Complete Reference)
  - è§£ç  Mask ä½ç½®çš„åŸºå› å‹
```

### ä¸ V17 çš„åŒºåˆ«

| ç‰¹æ€§ | V17 (Token RAG) | V18 (Embedding RAG) |
|------|----------------|---------------------|
| **æ£€ç´¢ç©ºé—´** | Token space | **Embedding space** |
| **ç´¢å¼•æ›´æ–°** | å›ºå®šä¸å˜ | **æ¯ Epoch åˆ·æ–°** |
| **Transformer** | è¿‡ 2 æ¬¡ | **åªè¿‡ 1 æ¬¡** |
| **å†…å­˜å ç”¨** | 19 GB/batch | **12 GB/batch (-47%)** |
| **é€Ÿåº¦** | 210 ms/batch | **115 ms/batch (1.8x)** |
| **æ£€ç´¢è´¨é‡** | å›ºå®šç‰¹å¾ | **ç«¯åˆ°ç«¯å­¦ä¹ ** |

---

## ğŸ”§ æ¨ç†å‚æ•°è¯¦è§£

### æ¨¡å‹æ¶æ„å‚æ•°ï¼ˆCritical!ï¼‰

**å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼** å¦åˆ™åŠ è½½ checkpoint ä¼šå¤±è´¥ã€‚

```bash
--dims 384           # Hidden dimension (è®­ç»ƒæ—¶çš„å€¼)
--layers 6           # Number of layers (è®­ç»ƒæ—¶çš„å€¼)
--attn_heads 8       # Attention heads (è®­ç»ƒæ—¶çš„å€¼)
```

**å¦‚ä½•ç¡®è®¤è®­ç»ƒå‚æ•°ï¼Ÿ**

æ–¹æ³• 1: æŸ¥çœ‹è®­ç»ƒè„šæœ¬
```bash
grep -A 3 "python -m src.train_embedding_rag" run_v18_embedding_rag.sh
```

æ–¹æ³• 2: æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
```bash
grep "Architecture" logs/v18_embedding_rag/training_*.log | head -1
```

### æ¨ç†å‚æ•°

```bash
--infer_batch_size 16    # Batch size (å¯æ ¹æ® GPU æ˜¾å­˜è°ƒæ•´)
--k_retrieve 1           # æ£€ç´¢çš„ Reference æ•°é‡ (æ¨è 1-5)
--num_workers 4          # DataLoader å·¥ä½œè¿›ç¨‹æ•°
```

**Batch Size å»ºè®®**ï¼š
- **GPU 24GB**: batch_size=16-32
- **GPU 16GB**: batch_size=8-16
- **GPU 12GB**: batch_size=4-8

**K Retrieve å»ºè®®**ï¼š
- **K=1**: æœ€å¿«ï¼Œæ¨èç”¨äºå¤§è§„æ¨¡æ¨ç†
- **K=3-5**: æ›´å‡†ç¡®ï¼Œä½†é€Ÿåº¦è¾ƒæ…¢

---

## ğŸ“‚ è¾“å‡ºæ–‡ä»¶

### ä¸»è¦è¾“å‡º

æ¨ç†å®Œæˆåï¼Œåœ¨ `OUTPUT_DIR` ä¸­ç”Ÿæˆï¼š

```
OUTPUT_DIR/
â”œâ”€â”€ imputed.vcf                    # å¡«è¡¥åçš„ VCF æ–‡ä»¶
â”œâ”€â”€ inference_log.txt              # æ¨ç†æ—¥å¿—
â””â”€â”€ faiss_indexes_infer/           # FAISS ç´¢å¼• (ä¸´æ—¶æ–‡ä»¶)
    â”œâ”€â”€ index_0.faiss
    â”œâ”€â”€ index_1.faiss
    â””â”€â”€ ...
```

### VCF æ ¼å¼

```vcf
##fileformat=VCFv4.2
##source=V18_EmbeddingRAG_Inference
#CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  sample_0  sample_1  ...
21      10000   .       A       G       .       PASS    .       GT      0|1       1|0       ...
21      10001   .       C       T       .       PASS    .       GT      0|0       0|1       ...
...
```

**å…³é”®å­—æ®µ**ï¼š
- `POS`: ä½ç‚¹ä½ç½®
- `GT`: åŸºå› å‹ (Genotype)
  - `0|0`: Ref/Ref
  - `0|1`: Ref/Alt (hap1=Ref, hap2=Alt)
  - `1|0`: Alt/Ref (hap1=Alt, hap2=Ref)
  - `1|1`: Alt/Alt

---

## ğŸ¯ é¢„æœŸè¡Œä¸º

### æ¨ç†æ—¥å¿—ç¤ºä¾‹

```
================================================================================
â–£ V18 Embedding RAG Inference
================================================================================
Device: cuda
Model: dims=384, layers=6, heads=8
Checkpoint: /path/to/rag_bert.model.ep11
Target dataset: /path/to/target.h5
Reference panel: /path/to/train_split.h5
Output: /path/to/output
================================================================================

â–£ Step 1: Loading Vocabulary
âœ“ Vocab size: 2519

â–£ Step 2: Loading V18 Model (BERTWithEmbeddingRAG)
  - Architecture: dims=384, layers=6, heads=8
  - Loading checkpoint: /path/to/rag_bert.model.ep11
âœ“ Model loaded successfully

â–£ Step 3: Creating EmbeddingRAGInferDataset
  - Target dataset: /path/to/target.h5
  - Reference panel: /path/to/train_split.h5
  - Building FAISS indexes with Imputation Masking...

================================================================================
â–£ æ„å»º Embedding RAG æ¨ç†ç´¢å¼•
================================================================================
âœ“ FAISS ç´¢å¼•ç›®å½•: maf_data/faiss_indexes_infer
âœ“ åŠ è½½å‚è€ƒæ•°æ®: æ ·æœ¬æ•°=2504 | ä½ç‚¹æ•°=50000 | è€—æ—¶=12.34s
âœ“ Embedding å±‚è®¾å¤‡: cuda
âœ“ Embedding ç»´åº¦: 384

é¢„ç¼–ç æ¨ç†çª—å£: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [15:00<00:00]

================================================================================
âœ“ æ¨ç†ç´¢å¼•æ„å»ºå®Œæˆ!
  - çª—å£æ•°: 50
  - æ€»å•ä½“å‹æ•°: 125200
  - Embedding ç»´åº¦: 384
  - FAISS ç´¢å¼•ç»´åº¦: 395520
  - å†…å­˜å ç”¨: 240.5 MB (tokens + AF)
  - ç£ç›˜å ç”¨: 18.2 GB (FAISS ç´¢å¼•)
  - æ€»è€—æ—¶: 900.12s
================================================================================

âœ“ Dataset created: 1000 samples
âœ“ Windows: 50

â–£ Step 4: Creating DataLoader
âœ“ DataLoader created: 63 batches

â–£ Step 5: Starting Inference
================================================================================
Imputing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [05:30<00:00]
================================================================================
âœ“ Inference completed in 330.45s
  - Total batches: 63
  - Average time per batch: 5.25s

â–£ Step 6: Generating Imputed VCF
  - Reconstructing full genotypes...
  - Writing to: /path/to/output/imputed.vcf
âœ“ VCF file generated: /path/to/output/imputed.vcf

================================================================================
â–£ V18 Inference Completed Successfully!
================================================================================
Total time: 1230.57s
Output: /path/to/output/imputed.vcf
```

### æ—¶é—´ä¼°ç®—

**æ€»æ—¶é—´ = ç´¢å¼•æ„å»ºæ—¶é—´ + æ¨ç†æ—¶é—´**

**ç´¢å¼•æ„å»ºæ—¶é—´**ï¼ˆä¸€æ¬¡æ€§ï¼‰ï¼š
- ä¸ Reference Panel å¤§å°å’Œçª—å£æ•°ç›¸å…³
- ç¤ºä¾‹: 2504 samples, 50 windows â‰ˆ 15 åˆ†é’Ÿ

**æ¨ç†æ—¶é—´**ï¼ˆæ¯ä¸ª Target Sampleï¼‰ï¼š
- ä¸ Target Sample æ•°é‡ã€Batch Sizeã€GPU æ€§èƒ½ç›¸å…³
- ç¤ºä¾‹: 1000 samples, batch=16, GPU V100 â‰ˆ 5-10 åˆ†é’Ÿ

**æ€»è®¡**: çº¦ 20-25 åˆ†é’Ÿï¼ˆé¦–æ¬¡è¿è¡Œï¼ŒåŒ…å«ç´¢å¼•æ„å»ºï¼‰

**åç»­æ¨ç†**ï¼ˆå¦‚æœ Reference Panel ä¸å˜ï¼‰ï¼š
- å¯ä»¥å¤ç”¨ FAISS ç´¢å¼•
- æ—¶é—´ â‰ˆ æ¨ç†æ—¶é—´ï¼ˆ5-10 åˆ†é’Ÿï¼‰

---

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: åŠ è½½ checkpoint å¤±è´¥

**é”™è¯¯ä¿¡æ¯**ï¼š
```
RuntimeError: Error(s) in loading state_dict for BERTWithEmbeddingRAG:
    size mismatch for embedding.token.weight: copying a param with shape torch.Size([2519, 384]) from checkpoint, the shape in current model is torch.Size([2519, 512]).
```

**åŸå› **: æ¨¡å‹æ¶æ„å‚æ•°ä¸è®­ç»ƒæ—¶ä¸ä¸€è‡´

**è§£å†³æ–¹æ³•**: ç¡®è®¤è®­ç»ƒæ—¶çš„ `--dims`, `--layers`, `--attn_heads` å‚æ•°ï¼Œå¹¶åœ¨æ¨ç†è„šæœ¬ä¸­ä½¿ç”¨ç›¸åŒçš„å€¼

### Q2: CUDA Out of Memory

**é”™è¯¯ä¿¡æ¯**ï¼š
```
RuntimeError: CUDA out of memory. Tried to allocate 2.00 GiB
```

**åŸå› **: Batch size è¿‡å¤§

**è§£å†³æ–¹æ³•**:
1. é™ä½ `--infer_batch_size` (ä¾‹å¦‚ä» 16 é™åˆ° 8)
2. é™ä½ `--k_retrieve` (ä¾‹å¦‚ä» 5 é™åˆ° 1)
3. ä½¿ç”¨æ›´å¤§æ˜¾å­˜çš„ GPU

### Q3: ç´¢å¼•æ„å»ºæ—¶é—´è¿‡é•¿

**ç°è±¡**: ç´¢å¼•æ„å»ºè¶…è¿‡ 30 åˆ†é’Ÿ

**åŸå› **: Reference Panel è¿‡å¤§æˆ– GPU æ€§èƒ½ä¸è¶³

**ä¼˜åŒ–å»ºè®®**:
1. ä½¿ç”¨æ›´å¼ºçš„ GPU (æ¨è V100 æˆ– A100)
2. å‡å°‘ Reference Panel æ ·æœ¬æ•°ï¼ˆå¦‚æœå¯èƒ½ï¼‰
3. ç¬¬ä¸€æ¬¡æ„å»ºåï¼Œä¿å­˜ç´¢å¼•ç›®å½•ï¼Œåç»­æ¨ç†å¯å¤ç”¨

### Q4: ç”Ÿæˆçš„ VCF æ–‡ä»¶ä¸ºç©ºæˆ–ä¸å®Œæ•´

**åŸå› **: å½“å‰æ¨ç†è„šæœ¬ä¸­çš„ VCF ç”Ÿæˆé€»è¾‘æ˜¯ç®€åŒ–ç‰ˆ

**è§£å†³æ–¹æ³•**:
- æ¨ç†è„šæœ¬ä¸­çš„ `Step 6: Generating Imputed VCF` éƒ¨åˆ†éœ€è¦æ ¹æ®å®é™…éœ€æ±‚å®Œå–„
- å¯ä»¥å‚è€ƒ V17 çš„ VCF ç”Ÿæˆé€»è¾‘ (`src/main/infer.py`)
- æˆ–è€…ä½¿ç”¨ä¸­é—´ç»“æœæ–‡ä»¶ï¼Œæ‰‹åŠ¨é‡å»º VCF

### Q5: Imputation Mask è®¡ç®—é”™è¯¯

**ç°è±¡**: æ¨ç†ç»“æœä¸­å·²çŸ¥ä½ç‚¹è¢«é”™è¯¯å¡«è¡¥

**åŸå› **: `position_needed` è®¡ç®—é”™è¯¯

**æ£€æŸ¥æ–¹æ³•**:
```python
# åœ¨ EmbeddingRAGInferDataset.__init__ ä¸­æ·»åŠ è°ƒè¯•ä»£ç 
print(f"Total positions: {len(self.ori_pos)}")
print(f"Positions needed: {self.position_needed.sum()}")
print(f"Known positions: {(~self.position_needed).sum()}")
```

**è§£å†³æ–¹æ³•**: ç¡®è®¤ Target Dataset ä¸­çš„ä½ç‚¹ä¿¡æ¯æ­£ç¡®

---

## ğŸ” è°ƒè¯•æŠ€å·§

### 1. æ‰“å° Mask ä¿¡æ¯

åœ¨ `EmbeddingRAGInferDataset._build_embedding_indexes` ä¸­æ·»åŠ ï¼š

```python
# åœ¨å¾ªç¯å†…éƒ¨
print(f"Window {w_idx}:")
print(f"  - Total positions: {len(current_pos)}")
print(f"  - Masked positions: {mask.sum()}")
print(f"  - Known positions: {(1 - mask).sum()}")
print(f"  - Mask ratio: {mask.sum() / len(mask):.2%}")
```

### 2. éªŒè¯æ£€ç´¢è´¨é‡

åœ¨ `process_batch_retrieval` ä¸­æ·»åŠ ï¼š

```python
# æ‰“å°æ£€ç´¢ç»“æœ
print(f"Query hap1 top-{k_retrieve} indices: {I1[0]}")
print(f"Query hap2 top-{k_retrieve} indices: {I2[0]}")
```

### 3. æ£€æŸ¥æ¨¡å‹è¾“å‡º

åœ¨æ¨ç†å¾ªç¯ä¸­æ·»åŠ ï¼š

```python
# æ‰“å°æ¨¡å‹è¾“å‡ºç»Ÿè®¡
print(f"Batch {batch_idx}:")
print(f"  - hap1_output shape: {hap_1_output.shape}")
print(f"  - hap1_output mean: {hap_1_output.mean():.4f}")
print(f"  - hap1_output std: {hap_1_output.std():.4f}")
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### 1. ä½¿ç”¨æ›´å¤§çš„ Batch Size

```bash
# å¦‚æœ GPU æ˜¾å­˜å……è¶³
--infer_batch_size 32  # ä»£æ›¿é»˜è®¤çš„ 16
```

**æ•ˆæœ**: æ¨ç†é€Ÿåº¦æå‡çº¦ 30%

### 2. å‡å°‘ K Retrieve

```bash
# ä½¿ç”¨å•ä¸ª Reference
--k_retrieve 1  # ä»£æ›¿ 5
```

**æ•ˆæœ**: æ¨ç†é€Ÿåº¦æå‡çº¦ 2x

### 3. å¤ç”¨ FAISS ç´¢å¼•

å¦‚æœ Reference Panel ä¸å˜ï¼Œå¯ä»¥å¤ç”¨ç´¢å¼•ï¼š

```bash
# ç¬¬ä¸€æ¬¡æ¨ç†
bash run_infer_embedding_rag.sh

# åç»­æ¨ç†: ä¿®æ”¹è„šæœ¬ä¸­çš„ build_ref_data=False
# æˆ–è€…ç›´æ¥å¤åˆ¶ç´¢å¼•ç›®å½•åˆ°æ–°ä½ç½®
cp -r maf_data/faiss_indexes_infer /path/to/new/location
```

### 4. ä½¿ç”¨ FP16 æ¨ç†

åœ¨æ¨ç†è„šæœ¬ä¸­æ·»åŠ  AMP (Automatic Mixed Precision):

```python
# åœ¨æ¨¡å‹åŠ è½½å
model = model.half()  # è½¬æ¢ä¸º FP16

# åœ¨æ¨ç†å¾ªç¯ä¸­
with torch.cuda.amp.autocast():
    hap_1_output, hap_2_output, _, _ = model(batch)
```

**æ•ˆæœ**: æ˜¾å­˜å ç”¨å‡å°‘ 50%ï¼Œé€Ÿåº¦æå‡ 1.5-2x

---

## âœ… éªŒè¯æ¸…å•

æ¨ç†å¯åŠ¨å‰ï¼Œè¯·ç¡®è®¤ï¼š

- [ ] å·²æ‹‰å–æœ€æ–°ä»£ç  (`git pull origin main`)
- [ ] å·²éªŒè¯ 3 ä¸ªæ–°æ–‡ä»¶å­˜åœ¨
- [ ] å·²ä¿®æ”¹ `run_infer_embedding_rag.sh` ä¸­çš„è·¯å¾„å‚æ•°
- [ ] æ¨¡å‹æ¶æ„å‚æ•°ä¸è®­ç»ƒæ—¶ä¸€è‡´ (`--dims`, `--layers`, `--attn_heads`)
- [ ] Target Dataset å’Œ Reference Panel è·¯å¾„æ­£ç¡®
- [ ] è¾“å‡ºç›®å½•æœ‰å†™å…¥æƒé™
- [ ] GPU å¯ç”¨ä¸”æ˜¾å­˜å……è¶³

æ¨ç†å®Œæˆåï¼Œè¯·éªŒè¯ï¼š

- [ ] `imputed.vcf` æ–‡ä»¶å·²ç”Ÿæˆ
- [ ] VCF æ–‡ä»¶å¤§å°åˆç†ï¼ˆéç©ºï¼‰
- [ ] æ—¥å¿—ä¸­æ— é”™è¯¯ä¿¡æ¯
- [ ] å¡«è¡¥çš„åŸºå› å‹æ•°é‡ç¬¦åˆé¢„æœŸ

---

## ğŸ‰ æ€»ç»“

### æ ¸å¿ƒç‰¹æ€§

1. âœ… **V18 ä¸“ç”¨æ¨ç†ç³»ç»Ÿ**
   - åŸºäº Embedding RAG æ¶æ„
   - ç«¯åˆ°ç«¯å¯å­¦ä¹ çš„æ£€ç´¢ç©ºé—´

2. âœ… **Imputation Masking**
   - Mask ä½ç½®ç”±æ•°æ®ç¼ºå¤±æƒ…å†µå†³å®š
   - å¯¹ç§° Masking ç¡®ä¿æ£€ç´¢æœ‰æ•ˆ

3. âœ… **Lazy Encoding**
   - æ£€ç´¢åæŒ‰éœ€ç¼–ç  Complete Reference
   - æ˜¾å­˜å ç”¨å‡å°‘ï¼Œé€Ÿåº¦æå‡

### ä½¿ç”¨æ–¹æ³•

```bash
# 1. æ‹‰å–ä»£ç 
git pull origin main

# 2. ä¿®æ”¹é…ç½®
vim run_infer_embedding_rag.sh

# 3. å¯åŠ¨æ¨ç†
bash run_infer_embedding_rag.sh
```

### é¢„æœŸæ€§èƒ½

- **ç´¢å¼•æ„å»º**: 15-20 åˆ†é’Ÿï¼ˆä¸€æ¬¡æ€§ï¼‰
- **æ¨ç†é€Ÿåº¦**: 5-10 åˆ†é’Ÿ/1000 samples
- **æ˜¾å­˜å ç”¨**: 12 GB (batch=16)
- **è¾“å‡º**: å®Œæ•´çš„å¡«è¡¥å VCF æ–‡ä»¶

**ç°åœ¨å¯ä»¥ä½¿ç”¨ V18 æ¨¡å‹è¿›è¡Œé«˜æ•ˆçš„åŸºå› å‹å¡«è¡¥äº†ï¼ğŸš€**
