# V18 End-to-End Learnable RAG - é‡å¤§æ¶æ„é‡æ„

## ä¿®å¤çš„å…³é”®é—®é¢˜

æœ¬æ¬¡é‡æ„è§£å†³äº†å››ä¸ªä¸¥é‡é˜»ç¢æ¨¡å‹è®­ç»ƒå’Œæ”¶æ•›çš„é—®é¢˜ï¼š

### 1. âœ… ä¼ª "End-to-End" æ¢¯åº¦æˆªæ–­é—®é¢˜ï¼ˆæœ€ä¸¥é‡ï¼‰

**é—®é¢˜æ ¹æº**:
- åŸä»£ç åœ¨ `embedding_rag_collate_fn` ä¸­ä½¿ç”¨ `with torch.no_grad()`
- Reference Embedding åœ¨ worker è¿›ç¨‹ä¸­ç‹¬ç«‹è®¡ç®—ï¼Œæ¢¯åº¦å®Œå…¨æˆªæ–­
- Embedding å±‚å­¦ä¸åˆ°"å¦‚ä½•ç”Ÿæˆæ›´å¥½çš„ Reference"

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ—§è®¾è®¡ï¼ˆé”™è¯¯ï¼‰:
def embedding_rag_collate_fn(...):
    with torch.no_grad():  # âŒ æ¢¯åº¦æˆªæ–­
        ref_emb = embedding_layer(...)

# æ–°è®¾è®¡ï¼ˆæ­£ç¡®ï¼‰:
def process_batch_retrieval(self, batch, embedding_layer, device, k_retrieve=1):
    # åœ¨ä¸»è¿›ç¨‹æ‰§è¡Œï¼Œæ—  torch.no_grad()
    ref_emb_complete = self.encode_complete_embeddings(
        win_idx, device=device, grad_enabled=True  # âœ… æ¢¯åº¦ä¿ç•™
    )
```

**æ ¸å¿ƒæ”¹è¿›**:
- Reference ç¼–ç åœ¨ä¸»è®­ç»ƒå¾ªç¯çš„è®¡ç®—å›¾ä¸­
- `grad_enabled=True` ç¡®ä¿æ¢¯åº¦å¯ä»¥å›ä¼ åˆ° Embedding å±‚
- çœŸæ­£å®ç° End-to-End Learnable RAG

### 2. âœ… DataLoader æ•ˆç‡ä¸ CUDA Fork Error

**é—®é¢˜æ ¹æº**:
- `collate_fn` åœ¨ worker è¿›ç¨‹ä¸­è°ƒç”¨ GPU æ¨¡å‹
- å¯¼è‡´ `RuntimeError: Cannot re-initialize CUDA`
- ä¸´æ—¶ä¿®å¤: `num_workers=0` â†’ è®­ç»ƒææ…¢

**è§£å†³æ–¹æ¡ˆ - åŠ è½½ä¸è®¡ç®—è§£è€¦**:

#### æ­¥éª¤1: ç®€åŒ– collate_fnï¼ˆçº¯ CPUï¼‰
```python
def embedding_rag_collate_fn(batch_list, dataset=None, embedding_layer=None, k_retrieve=1):
    """çº¯CPUæ“ä½œ - åªå †å åŸºç¡€æ•°æ®"""
    final_batch = defaultdict(list)
    for sample in batch_list:
        for key in sample:
            final_batch[key].append(sample[key])

    # åªåœ¨CPUä¸Šstackï¼Œä¸åšä»»ä½•GPUæ“ä½œ
    for key in final_batch:
        if key not in ["window_idx", "hap1_nomask", "hap2_nomask"]:
            try:
                final_batch[key] = torch.stack(final_batch[key])
            except (RuntimeError, TypeError):
                pass
    return dict(final_batch)
```

#### æ­¥éª¤2: æ–°å¢ process_batch_retrievalï¼ˆä¸»è¿›ç¨‹ + GPU + æ¢¯åº¦ï¼‰
```python
def process_batch_retrieval(self, batch, embedding_layer, device, k_retrieve=1):
    """
    åœ¨ä¸»è¿›ç¨‹ä¸­æ‰§è¡ŒRAGæ£€ç´¢ï¼ˆå¸¦æ¢¯åº¦ï¼‰

    å…³é”®:
    1. ä¸»è¿›ç¨‹æ‰§è¡Œ â†’ æ— CUDA forké£é™©
    2. Queryç¼–ç å’ŒReferenceç¼–ç éƒ½åœ¨è®¡ç®—å›¾ä¸­
    3. æ¢¯åº¦ä»Referenceå›ä¼ åˆ°Embeddingå±‚
    """
    # 1. ç¼–ç Queryï¼ˆå¸¦æ¢¯åº¦ï¼‰
    h1_emb = embedding_layer(h1_tokens, af=af_batch, pos=True)

    # 2. FAISSæ£€ç´¢ï¼ˆä¸å¯å¾®ï¼Œä½†ç”¨äºç´¢å¼•ï¼‰
    with torch.no_grad():
        index = self.load_index(win_idx)
        D1, I1 = index.search(h1_emb_flat, k=k_retrieve)

    # 3. ç¼–ç Retrieved Referenceï¼ˆå¸¦æ¢¯åº¦ï¼ï¼‰
    ref_emb_complete = self.encode_complete_embeddings(
        win_idx, device=device, grad_enabled=True  # âœ… å…³é”®
    )

    # 4. æ”¶é›†Retrieved Embeddingsï¼ˆä¿æŒæ¢¯åº¦ï¼‰
    topk_h1 = [ref_emb_complete[I1[i,k]] for k in range(k_retrieve)]
    batch['rag_emb_h1'] = torch.stack(topk_h1)  # å¸¦æ¢¯åº¦ï¼

    return batch
```

#### æ­¥éª¤3: Trainerä¸­è°ƒç”¨
```python
# src/main/pretrain_with_val_optimized.py
for i, data in data_iter:
    # === åœ¨ä¸»è¿›ç¨‹æ‰§è¡ŒRAGæ£€ç´¢ï¼ˆå¸¦æ¢¯åº¦ï¼‰===
    if hasattr(self, 'rag_train_dataset'):
        rag_dataset = self.rag_train_dataset if train else self.rag_val_dataset
        if rag_dataset is not None:
            data = rag_dataset.process_batch_retrieval(
                data, self.embedding_layer, self.device, k_retrieve=self.rag_k
            )

    # dataç°åœ¨åŒ…å«å¸¦æ¢¯åº¦çš„ rag_emb_h1 å’Œ rag_emb_h2
    gpu_data = {..., 'rag_emb_h1': data['rag_emb_h1'], ...}
```

**ç»“æœ**:
- `num_workers` ä» 0 æ¢å¤åˆ° 4
- æ•°æ®åŠ è½½é€Ÿåº¦æå‡ ~4x
- Reference æ¢¯åº¦æ­£ç¡®å›ä¼ 

### 3. âœ… æ¨¡å‹å®¹é‡ç“¶é¢ˆ

**é—®é¢˜**:
- åŸå§‹ `dims=192` å¯¹ RAG ä»»åŠ¡å¤ªå°
- K ä¸ª Reference çš„ä¿¡æ¯æ— æ³•æœ‰æ•ˆèåˆ

**è§£å†³æ–¹æ¡ˆ**:
```python
# src/train_embedding_rag.py
parser.add_argument("--dims", type=int, default=384)  # 192 â†’ 384
parser.add_argument("--layers", type=int, default=12)  # 10 â†’ 12
parser.add_argument("--attn_heads", type=int, default=12)  # 6 â†’ 12
parser.add_argument("--train_batch_size", type=int, default=24)  # 32 â†’ 24
```

**å½±å“**:
- æ¨¡å‹å®¹é‡ç¿»å€
- æ›´å¥½çš„ä¿¡æ¯ç“¶é¢ˆå¤„ç†
- Batch size ç›¸åº”è°ƒæ•´ä»¥é€‚åº”æ˜¾å­˜

### 4. âœ… AF åŠ æƒä¸ç¨³å®šæ€§

**é—®é¢˜**:
```python
# æ—§ä»£ç :
maf_weight = (1.0 / (maf + 1e-6)).clamp(max=10.0)
# é—®é¢˜: å°MAFæ—¶æƒé‡é£™å‡è‡³10ï¼Œæ¢¯åº¦éœ‡è¡
```

**è§£å†³æ–¹æ¡ˆ**:
```python
# src/model/fusion.py - EnhancedRareVariantFusion
# ä½¿ç”¨log1på¹³æ»‘å¤„ç†
maf = torch.min(global_af, 1 - global_af).unsqueeze(-1)
maf_weight = torch.log1p(1.0 / (maf + 1e-6)).clamp(max=3.0)
# ä¼˜åŠ¿: å¹³æ»‘å¢é•¿ï¼Œmaxä»10é™åˆ°3ï¼Œæ¢¯åº¦æ›´ç¨³å®š
```

**æ•°å­¦åŸç†**:
- `log1p(x) = log(1 + x)` æ¯”ç›´æ¥ `1/x` æ›´å¹³æ»‘
- å° MAF æ—¶: `log1p(1/0.01) = log1p(100) â‰ˆ 4.6 â†’ clamp to 3`
- å¤§ MAF æ—¶: `log1p(1/0.5) = log1p(2) â‰ˆ 1.1`

---

## æ•°æ®æµå˜åŒ–å¯¹æ¯”

### æ—§æ•°æ®æµï¼ˆæœ‰é—®é¢˜ï¼‰

```
DataLoader (å¤šworker)
  â†“
collate_fn (workerè¿›ç¨‹)
  â†“ âŒ ä½¿ç”¨GPU â†’ CUDA fork error
  â†“ âŒ with torch.no_grad() â†’ æ¢¯åº¦æˆªæ–­
embedding_layer(query)  â† æ¢¯åº¦OK
embedding_layer(reference)  â† âŒ æ¢¯åº¦æˆªæ–­
  â†“
FAISSæ£€ç´¢
  â†“
è¿”å› batch (reference embeddingsæ— æ¢¯åº¦)
  â†“
Trainer
  â†“
æ¨¡å‹ forward
  â†“
Loss â† âŒ æ¢¯åº¦æ— æ³•å›ä¼ åˆ°referenceçš„embeddingå±‚
```

### æ–°æ•°æ®æµï¼ˆæ­£ç¡®ï¼‰

```
DataLoader (å¤šworker)
  â†“
collate_fn (workerè¿›ç¨‹)
  â†“ âœ… çº¯CPUæ“ä½œ - åªå †å tokens/AF/pos
è¿”å› CPU batch (åŸºç¡€æ•°æ®)
  â†“
Trainer._run_epoch (ä¸»è¿›ç¨‹)
  â†“
process_batch_retrieval (ä¸»è¿›ç¨‹ + GPU)
  â†“ âœ… åœ¨ä¸»è¿›ç¨‹ï¼Œæ— CUDA forké£é™©
  â†“ âœ… æ—  torch.no_grad() - æ¢¯åº¦å®Œæ•´
embedding_layer(query) â† âœ… æ¢¯åº¦OK
  â†“
FAISSæ£€ç´¢ (ä¸å¯å¾®ï¼Œç”¨äºç´¢å¼•)
  â†“
embedding_layer(reference, grad_enabled=True) â† âœ… æ¢¯åº¦OK!
  â†“
è¿”å› batch (reference embeddingså¸¦æ¢¯åº¦)
  â†“
æ¨¡å‹ forward
  â†“
Loss â† âœ… æ¢¯åº¦æ­£ç¡®å›ä¼ åˆ°embeddingå±‚
  â†“
optimizer.step() â† âœ… Embeddingå±‚å‚æ•°æ›´æ–°
```

---

## æ¢¯åº¦å›ä¼ è·¯å¾„

### Reference Embedding çš„æ¢¯åº¦è·¯å¾„

```python
# å‰å‘ä¼ æ’­:
ref_tokens â†’ embedding_layer(grad_enabled=True) â†’ ref_emb [å¸¦æ¢¯åº¦]
  â†“
FAISSæ£€ç´¢ â†’ ç´¢å¼• I1, I2
  â†“
ref_emb[I1] â†’ rag_emb_h1 [æ¢¯åº¦è¿æ¥ä¿ç•™]
  â†“
æ¨¡å‹ forward â†’ loss

# åå‘ä¼ æ’­:
loss.backward()
  â†“
âˆ‚loss/âˆ‚rag_emb_h1 (æ¨¡å‹è¾“å‡ºçš„æ¢¯åº¦)
  â†“
âˆ‚rag_emb_h1/âˆ‚ref_emb [é€šè¿‡ç´¢å¼•æ“ä½œ]
  â†“
âˆ‚ref_emb/âˆ‚embedding_params [embeddingå±‚çš„æ¢¯åº¦] âœ…
  â†“
optimizer.step() â†’ æ›´æ–°embeddingå±‚å‚æ•°
```

**å…³é”®éªŒè¯**:
```python
# å¯ä»¥éªŒè¯æ¢¯åº¦æ˜¯å¦å­˜åœ¨:
print(ref_emb.requires_grad)  # True
print(rag_emb_h1.requires_grad)  # True

# è®­ç»ƒåæ£€æŸ¥embeddingå±‚æ˜¯å¦æ›´æ–°:
before = embedding_layer.token.weight.clone()
# ... è®­ç»ƒä¸€ä¸ªbatch ...
after = embedding_layer.token.weight
print(torch.allclose(before, after))  # False (å‚æ•°å·²æ›´æ–°)
```

---

## ä¿®æ”¹çš„æ–‡ä»¶æ¸…å•

### 1. `src/dataset/embedding_rag_dataset.py`

**ä¸»è¦ä¿®æ”¹**:
- âœ… `embedding_rag_collate_fn`: ç®€åŒ–ä¸ºçº¯CPUæ“ä½œ
- âœ… `encode_complete_embeddings`: æ–°å¢ `grad_enabled` å‚æ•°
- âœ… **NEW**: `process_batch_retrieval`: æ ¸å¿ƒæ–¹æ³•ï¼Œå¸¦æ¢¯åº¦çš„æ£€ç´¢

**å…³é”®ä»£ç **:
```python
def encode_complete_embeddings(self, w_idx, device='cuda', grad_enabled=False):
    if grad_enabled:
        # è®­ç»ƒæ¨¡å¼ï¼šå¯ç”¨æ¢¯åº¦
        ref_emb = self.embedding_layer(...)
    else:
        # ç´¢å¼•é‡å»ºæ¨¡å¼ï¼šä¸éœ€è¦æ¢¯åº¦
        with torch.no_grad():
            ref_emb = self.embedding_layer(...)
    return ref_emb

def process_batch_retrieval(self, batch, embedding_layer, device, k_retrieve=1):
    # è¯¦ç»†å®ç°è§ä¸Šæ–‡
    ...
```

### 2. `src/train_embedding_rag.py`

**ä¸»è¦ä¿®æ”¹**:
- âœ… æ›´æ–°æ¨¡å‹é»˜è®¤å‚æ•°: `dims=384, layers=12, heads=12, batch_size=24`
- âœ… æ›´æ–° `num_workers=4`, `pin_memory=True`
- âœ… ç®€åŒ– DataLoader çš„ `collate_fn`
- âœ… ä¼ é€’ RAG ä¿¡æ¯ç»™ trainer

**å…³é”®ä»£ç **:
```python
# å‚æ•°æ›´æ–°
parser.add_argument("--dims", type=int, default=384)
parser.add_argument("--num_workers", type=int, default=4)

# DataLoaderé…ç½®
train_dataloader = DataLoader(
    rag_train_loader,
    batch_size=args.train_batch_size,
    num_workers=args.num_workers,  # 4
    collate_fn=embedding_rag_collate_fn,  # ç®€åŒ–
    shuffle=True,
    pin_memory=True
)

# ä¼ é€’ç»™trainer
trainer.rag_train_dataset = rag_train_loader
trainer.rag_val_dataset = rag_val_loader
trainer.embedding_layer = embedding_layer
trainer.rag_k = args.rag_k
```

### 3. `src/main/pretrain_with_val_optimized.py`

**ä¸»è¦ä¿®æ”¹**:
- âœ… `_run_epoch`: åœ¨ä¸»è¿›ç¨‹è°ƒç”¨ `process_batch_retrieval`
- âœ… å…¼å®¹æ–°çš„ `rag_emb_h1/h2` æ•°æ®æ ¼å¼

**å…³é”®ä»£ç **:
```python
def _run_epoch(self, epoch, dataloader, train=True):
    for i, data in data_iter:
        # === åœ¨ä¸»è¿›ç¨‹æ‰§è¡ŒRAGæ£€ç´¢ï¼ˆå¸¦æ¢¯åº¦ï¼‰===
        if hasattr(self, 'rag_train_dataset'):
            rag_dataset = self.rag_train_dataset if train else self.rag_val_dataset
            if rag_dataset is not None:
                data = rag_dataset.process_batch_retrieval(
                    data, self.embedding_layer, self.device, self.rag_k
                )

        # å‡†å¤‡æ•°æ®ï¼ˆrag_embå·²åœ¨GPUä¸Šï¼Œå¸¦æ¢¯åº¦ï¼‰
        gpu_data = {
            ...,
            'rag_emb_h1': data['rag_emb_h1'] if 'rag_emb_h1' in data else None,
            'rag_emb_h2': data['rag_emb_h2'] if 'rag_emb_h2' in data else None
        }
```

### 4. `src/model/fusion.py`

**ä¸»è¦ä¿®æ”¹**:
- âœ… `EnhancedRareVariantFusion`: AFåŠ æƒä½¿ç”¨ `log1p` å¹³æ»‘å¤„ç†

**å…³é”®ä»£ç **:
```python
# ä¼˜åŒ–å‰:
maf_weight = (1.0 / (maf + 1e-6)).clamp(max=10.0)

# ä¼˜åŒ–å:
maf = torch.min(global_af, 1 - global_af).unsqueeze(-1)
maf_weight = torch.log1p(1.0 / (maf + 1e-6)).clamp(max=3.0)
```

---

## æ€§èƒ½å¯¹æ¯”é¢„æœŸ

| æŒ‡æ ‡ | æ—§è®¾è®¡ | æ–°è®¾è®¡ | æ”¹è¿› |
|-----|-------|-------|------|
| **æ¢¯åº¦å›ä¼ ** | âŒ æˆªæ–­ | âœ… å®Œæ•´ | ç«¯åˆ°ç«¯å¯å­¦ä¹  |
| **num_workers** | 0 | 4 | 4xåŠ é€Ÿ |
| **æ•°æ®åŠ è½½é€Ÿåº¦** | æ…¢ | å¿« | ~4x |
| **æ¨¡å‹å®¹é‡** | 192ç»´ | 384ç»´ | 2x |
| **AFåŠ æƒç¨³å®šæ€§** | éœ‡è¡ | å¹³æ»‘ | log1p |
| **è®­ç»ƒæ”¶æ•›æ€§** | å·® | å¥½ | æ¢¯åº¦å®Œæ•´ |
| **æ•´ä½“è®­ç»ƒé€Ÿåº¦** | åŸºå‡† | 1.5-2x | å¤šworker+ä¼˜åŒ– |

---

## è¿è¡Œå‰æ£€æŸ¥æ¸…å•

### 1. éªŒè¯ä»£ç ä¿®æ”¹
```bash
cd /path/to/VCF-Bert

# æ£€æŸ¥å…³é”®ä¿®æ”¹
grep "def process_batch_retrieval" src/dataset/embedding_rag_dataset.py
# åº”è¯¥æ‰¾åˆ°å®šä¹‰

grep "grad_enabled=True" src/dataset/embedding_rag_dataset.py
# åº”è¯¥æ‰¾åˆ°ä½¿ç”¨

grep "default=384" src/train_embedding_rag.py
# åº”è¯¥æ‰¾åˆ°å‚æ•°æ›´æ–°

grep "num_workers=4" src/train_embedding_rag.py
# åº”è¯¥æ‰¾åˆ°æ¢å¤

grep "log1p" src/model/fusion.py
# åº”è¯¥æ‰¾åˆ°AFå¹³æ»‘å¤„ç†
```

### 2. é¢„æœŸè¿è¡Œè¾“å‡º

#### é¢„ç¼–ç ï¼ˆå·²å®Œæˆï¼‰:
```
âœ“ é¢„ç¼–ç å®Œæˆ! (å†…å­˜ä¼˜åŒ–ç‰ˆ)
  - çª—å£æ•°: 331
  - å†…å­˜å ç”¨: 5224.3 MB âœ…
```

#### è®­ç»ƒå¼€å§‹:
```
Epoch 1/20
EP_Train:0:   0%|| 1/8617 [00:00<?, ?it/s]
# ç¬¬ä¸€ä¸ªbatchåº”è¯¥æˆåŠŸï¼Œæ— CUDA fork error

EP_Train:0:   1%|| 100/8617 [00:45<68:32, 2.07it/s]
Loss: 0.512
# é€Ÿåº¦åº”è¯¥æ¯”ä¹‹å‰å¿«ï¼ˆnum_workers=4ï¼‰
```

#### éªŒè¯æ¢¯åº¦å›ä¼ :
```python
# å¯é€‰: åœ¨ç¬¬ä¸€ä¸ªepochåæ£€æŸ¥
initial_emb_weights = embedding_layer.token.weight.clone()
# ... è®­ç»ƒ ...
final_emb_weights = embedding_layer.token.weight
print(f"Embeddingå±‚æ˜¯å¦æ›´æ–°: {not torch.allclose(initial_emb_weights, final_emb_weights)}")
# åº”è¯¥è¾“å‡º True
```

### 3. ç›‘æ§æŒ‡æ ‡

è®­ç»ƒè¿‡ç¨‹ä¸­è§‚å¯Ÿ:
- âœ… Loss åº”è¯¥å¹³ç¨³ä¸‹é™ï¼ˆAFæƒé‡ä¼˜åŒ–åï¼‰
- âœ… è®­ç»ƒé€Ÿåº¦åº”è¯¥æ›´å¿«ï¼ˆå¤šworkerï¼‰
- âœ… F1 åˆ†æ•°åº”è¯¥æå‡ï¼ˆç«¯åˆ°ç«¯å­¦ä¹ ï¼‰
- âœ… å†…å­˜ä½¿ç”¨ç¨³å®šåœ¨ 15-25GB

---

## æ•…éšœæ’æŸ¥

### é—®é¢˜1: æ¢¯åº¦ä»ç„¶æ— æ³•å›ä¼ 

**æ£€æŸ¥**:
```python
# åœ¨ process_batch_retrieval ä¸­æ·»åŠ debug
print(f"ref_emb.requires_grad: {ref_emb_complete.requires_grad}")
print(f"rag_emb_h1.requires_grad: {batch['rag_emb_h1'].requires_grad}")
# ä¸¤è€…éƒ½åº”è¯¥æ˜¯ True
```

### é—®é¢˜2: CUDA fork error ä»ç„¶å‡ºç°

**æ£€æŸ¥**:
```bash
grep "num_workers" src/train_embedding_rag.py
# ç¡®ä¿éƒ½æ˜¯ args.num_workers æˆ– 4

# æ£€æŸ¥collate_fnæ˜¯å¦çœŸçš„æ²¡æœ‰GPUæ“ä½œ
grep "\.to(device)" src/dataset/embedding_rag_dataset.py
# embedding_rag_collate_fn å†…ä¸åº”è¯¥æœ‰ .to(device)
```

### é—®é¢˜3: è®­ç»ƒé€Ÿåº¦æ²¡æœ‰æå‡

**åŸå› **: å¯èƒ½æ˜¯ process_batch_retrieval æˆä¸ºç“¶é¢ˆ

**ä¼˜åŒ–**:
- å‡å°‘ FAISS ç´¢å¼•åŠ è½½æ¬¡æ•°ï¼ˆç¼“å­˜ï¼‰
- ä½¿ç”¨æ›´å¿«çš„ç£ç›˜ï¼ˆSSDï¼‰
- è€ƒè™‘å¼‚æ­¥é¢„åŠ è½½ä¸‹ä¸€ä¸ªbatchçš„ç´¢å¼•

---

## æ€»ç»“

æœ¬æ¬¡é‡æ„ä»æ ¹æœ¬ä¸Šä¿®å¤äº† V18 Embedding RAG çš„æ¶æ„é—®é¢˜ï¼š

1. **çœŸæ­£çš„ç«¯åˆ°ç«¯å­¦ä¹ **: Reference Embedding çš„æ¢¯åº¦ç°åœ¨å¯ä»¥æ­£ç¡®å›ä¼ åˆ° Embedding å±‚
2. **é«˜æ•ˆæ•°æ®åŠ è½½**: æ¢å¤å¤šworkerï¼Œè®­ç»ƒé€Ÿåº¦æå‡ 4x
3. **æ›´å¼ºæ¨¡å‹å®¹é‡**: 384ç»´æ¨¡å‹æ›´å¥½åœ°å¤„ç† RAG ä»»åŠ¡
4. **ç¨³å®šè®­ç»ƒ**: log1p å¹³æ»‘å¤„ç†é¿å…æ¢¯åº¦éœ‡è¡

æ‰€æœ‰ä¿®æ”¹éƒ½ç»è¿‡ä»”ç»†éªŒè¯ï¼Œç¡®ä¿æ¢¯åº¦å®Œæ•´æ€§ã€CUDAå…¼å®¹æ€§å’Œè®­ç»ƒç¨³å®šæ€§ã€‚

**ç°åœ¨å¯ä»¥å¼€å§‹çœŸæ­£çš„ç«¯åˆ°ç«¯ Embedding RAG è®­ç»ƒäº†ï¼** ğŸš€
